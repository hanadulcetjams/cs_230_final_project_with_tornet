{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b99b3ba1-a966-4502-857f-ef0344d141be",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n",
    "The goal of this notebook is to use data augmentation to improve upon the results of the original TorNet baseline CNN model.\n",
    "\n",
    "In this notebook, we implement the image flipping used to only add flipped versions of tornado images to the TorNet dataset.\n",
    "We then take that data and re-train the original architecture of the TorNet model (albeit with our re-tuned hyperparameters\n",
    "for batch size and learning rate) in order to see whether the data augmentation strategy will improve the quality of the \n",
    "model that is trained by addressing the class imbalance due to the rarity of tornadoes in the dataset.\n",
    "\n",
    "Of note - as mentioned in the project milestone, we can't use region cropping or translation here, because the \n",
    "original data is radar data which is being measured on a slant (not top-down) and hence has a natural stretching/distortion\n",
    "that occurs depending on how far away a storm cell is from the center of the radar image. If we move the data around, \n",
    "we risk introducing our own squishing artifacts on the shapes of the cells which would poison our dataset. \n",
    "\n",
    "In comparison, mirroring here could be very helpful (without translating the data) to generate more examples of \n",
    "tornadoes without having to find more tornado radar images. Hence, we implement that strategy here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "052ae79f-b46e-47ec-b29d-4538a9233d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 15:29:03.236647: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-21 15:29:03.364149: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732231743.414687   23331 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732231743.430478   23331 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-21 15:29:03.553113: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# just the location for the input data\n",
    "TORNET_DATA_INPUT_FOLDER = \"/mnt/c/users/handypark/Documents/Grad_School_Courses/CS_230/tornet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e4063f0-8bf4-48f6-ad78-b602b3216db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngpus = tf.config.list_physical_devices(\\'GPU\\')\\nif gpus:\\n  try:\\n    # Currently, memory growth needs to be the same across GPUs\\n    for gpu in gpus:\\n      tf.config.experimental.set_memory_growth(gpu, True)\\n    logical_gpus = tf.config.list_logical_devices(\\'GPU\\')\\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\\n  except RuntimeError as e:\\n    # Memory growth must be set before GPUs have been initialized\\n    print(e)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just making sure that we are indeed using GPU-based Tensorflow and not CPU-based Tensorflow.\n",
    "tf.test.is_built_with_cuda()\n",
    "\n",
    "# We tried experimental memory growth in some cases, but it didn't work out well (also crashed a lot).\n",
    "\"\"\"\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677cb397-68c6-47a7-8a18-577995858d9e",
   "metadata": {},
   "source": [
    "## Creating a dataset with additional mirrored tornado examples\n",
    "\n",
    "This time around, now that we have the learning rate and batch size all tuned, we can start trying to improve the performance of the model.\n",
    "Our first idea is to try using data augmentation. Since examples of tornados are rare (and comprise only a tiny portion of the data),\n",
    "the hope here is to try to artificially increase the number of examples of tornadoes to help correct this class imbalance.\n",
    "\n",
    "The initial paper used weights on different kinds of examples, but the hope here is that augmenting the data can be even more effective.\n",
    "What we've done below is to take TorNet's dataset loading + creation code and introduce a flipping step, where we do the following:\n",
    "- Check if the given training set image is a tornadic example.\n",
    "- If not, proceed as normal.\n",
    "- If so, add another copy of the image that we have flipped to the training set.\n",
    "\n",
    "With this data augmentation, we're hoping to see some improvement in the performance of the model on the testing data in terms of AUC, just from the additional \"examples\" of tornados that we get a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59daf357-3d58-45a9-a8fd-4f8062907a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TorNet's data loading code, but now with some adjustments for data augmentation purposes.\n",
    "We create `create_tf_with_flips_dataset` in order to make a dataset that has both\n",
    "tornadic examples and mirrored tornadic examples.\n",
    "\"\"\"\n",
    "from typing import List, Dict\n",
    "\n",
    "from tornet.data.loader import query_catalog, read_file\n",
    "from tornet.data.constants import ALL_VARIABLES\n",
    "from tornet.data import preprocess as pp\n",
    "import numpy as np\n",
    "\n",
    "def create_tf_with_flips_dataset(files:str,\n",
    "                                 variables: List[str]=ALL_VARIABLES,\n",
    "                                 n_frames:int=1,\n",
    "                                 tilt_last: bool=True) -> tf.data.Dataset:\n",
    "    \"\"\"\n",
    "    This is Tornet's main function for loading the data from the folder where it's all stored, but we've \n",
    "    made adjustments to actually add a system for flipping tornadic images.\n",
    "\n",
    "    In this case, we add non-tornadic examples as normal, but when we encounter an example of\n",
    "    a tornado, we actually add both the original tornadic example and a mirrored version\n",
    "    of the tornadic example to the dataset.\n",
    "    \"\"\"\n",
    "    assert len(files)>0\n",
    "    \n",
    "    # grab one file to gets keys, shapes, etc\n",
    "    data = read_file(files[0],variables=variables,n_frames=n_frames, tilt_last=tilt_last)\n",
    "    \n",
    "    output_signature = { k:tf.TensorSpec(shape=data[k].shape,dtype=data[k].dtype,name=k) for k in data }\n",
    "\n",
    "    # Iterate through all the files and keep track of which are tornadic examples, and add \n",
    "    # a \"to-be-flipped\" copy for each case of a tornado.\n",
    "    file_list = []\n",
    "    for f in files:\n",
    "        file_list.append((f, 0))\n",
    "        file_dict = read_file(f,variables=variables,n_frames=n_frames, tilt_last=tilt_last)\n",
    "        if file_dict[\"label\"] == 1:\n",
    "            file_list.append((f, 1))\n",
    "\n",
    "    # When generating the data, check to see whether we should flip the data,\n",
    "    # then flip if necessary.\n",
    "    def gen():\n",
    "        for (f, flipper) in file_list:\n",
    "            file_dict = read_file(f,variables=variables,n_frames=n_frames, tilt_last=tilt_last)\n",
    "            if flipper == 1:\n",
    "                # Each of the 6 different radar images gets flipped using np.flip\n",
    "                for var in ['DBZ','VEL','KDP','RHOHV','ZDR','WIDTH']:\n",
    "                    file_dict[var] = tf.convert_to_tensor(np.flip(file_dict[var], 1))\n",
    "            yield file_dict\n",
    "    ds = tf.data.Dataset.from_generator(gen,\n",
    "                                        output_signature=output_signature)\n",
    "    return ds\n",
    "    \n",
    "\n",
    "def preproc(ds: tf.data.Dataset,\n",
    "            weights:Dict=None,\n",
    "            include_az:bool=False,\n",
    "            select_keys:list=None,\n",
    "            tilt_last:bool=True):\n",
    "    \"\"\"\n",
    "    This is Tornet's preprocessing function, unchanged,\n",
    "    for taking the raw dataset loaded from the files (in create_tf_dataset)\n",
    "    and then doing a few things:\n",
    "\n",
    "    - Remove the time dimension (since we only care about detection at a given time t)\n",
    "    - Add coordinates (so that we can run CoordConv layers later)\n",
    "    - Split the data into its inputs and label outputs\n",
    "    - Adding weights (if we decide to weight the data at all)\n",
    "\n",
    "    Once the preprocessing is done, the data is basically ready to be trained on.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove time dimension\n",
    "    ds = ds.map(pp.remove_time_dim)\n",
    "\n",
    "    # Add coordinate tensors\n",
    "    ds = ds.map(lambda d: pp.add_coordinates(d,include_az=include_az,tilt_last=tilt_last,backend=tf))\n",
    "\n",
    "    # split into X,y\n",
    "    ds = ds.map(pp.split_x_y)\n",
    "\n",
    "    # Add sample weights\n",
    "    if weights:\n",
    "        ds = ds.map(lambda x,y:  pp.compute_sample_weight(x,y,**weights, backend=tf) )\n",
    "    \n",
    "        # select keys for input\n",
    "        if select_keys is not None:\n",
    "            ds = ds.map(lambda x,y,w: (pp.select_keys(x,keys=select_keys),y,w))\n",
    "    else:\n",
    "        if select_keys is not None:\n",
    "            ds = ds.map(lambda x,y: (pp.select_keys(x,keys=select_keys),y))\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57fd9150-7c8c-4cea-bd85-4b862ad28639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tf_with_flips_loader(data_root: str, \n",
    "                              data_type:str='train', # or 'test'\n",
    "                              years: list=list(range(2013,2023)),\n",
    "                              batch_size: int=128, \n",
    "                              weights: Dict=None,\n",
    "                              include_az: bool=False,\n",
    "                              random_state:int=1234,\n",
    "                              select_keys: list=None,\n",
    "                              tilt_last: bool=True,\n",
    "                              from_tfds: bool=False,\n",
    "                              tfds_data_version: str='1.1.0',\n",
    "                              num_epochs: int=3):\n",
    "    \"\"\"\n",
    "    We've trimmed down the make_tf_loader function from the TorNet helper\n",
    "    functions to make clear which part of the loader we're using.\n",
    "\n",
    "    Now that we have a function for making a dataset with flipped tornado\n",
    "    examples added in, we make use of it here.\n",
    "    \"\"\"\n",
    "    # get files from the catalog\n",
    "    file_list = query_catalog(data_root, data_type, years, random_state)\n",
    "\n",
    "    # make the dataset using the flipped data generator\n",
    "    ds = create_tf_with_flips_dataset(file_list,variables=ALL_VARIABLES,n_frames=1, tilt_last=tilt_last) \n",
    "\n",
    "    # do the usual preprocessing to prepare the input for Tensorflow training\n",
    "    ds = preproc(ds,weights,include_az,select_keys,tilt_last)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # this has been adjusted to include drop_remainder=True\n",
    "    ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6414f3-a24c-4242-9c0a-0488d29b12ad",
   "metadata": {},
   "source": [
    "## TorNet Baseline CNN Model Definition:\n",
    "\n",
    "As stated in the comment for the code block below, this is just the TorNet model code that was used in the original paper.\n",
    "We'll be using the same model for now during our data augmentation experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d7d2e8a-6fdf-4017-a395-7a9fa08d8e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is just the TorNet model code that was used in the paper.\n",
    "Goal is to run this model which consists of:\n",
    "- Normalizing the inputs\n",
    "- Adding the coordinate information for CoordConv to work properly\n",
    "- Running 4 VGG blocks which each have CoordConv2D and two MAXPOOL layers\n",
    "- One last block of Conv2D layers and MAXPOOL to get the output probability\n",
    "\"\"\"\n",
    "\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "import keras\n",
    "from tornet.models.keras.layers import CoordConv2D, FillNaNs\n",
    "from tornet.data.constants import CHANNEL_MIN_MAX, ALL_VARIABLES\n",
    "\n",
    "\n",
    "def build_model(shape:Tuple[int]=(120,240,2),\n",
    "                c_shape:Tuple[int]=(120,240,2),\n",
    "                input_variables:List[str]=ALL_VARIABLES,\n",
    "                start_filters:int=64,\n",
    "                l2_reg:float=0.001,\n",
    "                background_flag:float=-3.0,\n",
    "                include_range_folded:bool=True,\n",
    "                head='maxpool'):\n",
    "    # Create input layers for each input_variables\n",
    "    inputs = {}\n",
    "    for v in input_variables:\n",
    "        inputs[v]=keras.Input(shape,name=v)\n",
    "    n_sweeps=shape[2]\n",
    "    \n",
    "    # Normalize inputs and concate along channel dim\n",
    "    normalized_inputs=keras.layers.Concatenate(axis=-1,name='Concatenate1')(\n",
    "        [normalize(inputs[v],v) for v in input_variables]\n",
    "        )\n",
    "\n",
    "    # Replace nan pixel with background flag\n",
    "    normalized_inputs = FillNaNs(background_flag)(normalized_inputs)\n",
    "\n",
    "    # Add channel for range folded gates \n",
    "    if include_range_folded:\n",
    "        range_folded = keras.Input(shape[:2]+(n_sweeps,),name='range_folded_mask')\n",
    "        inputs['range_folded_mask']=range_folded\n",
    "        normalized_inputs = keras.layers.Concatenate(axis=-1,name='Concatenate2')(\n",
    "               [normalized_inputs,range_folded])\n",
    "        \n",
    "    # Input coordinate information\n",
    "    cin=keras.Input(c_shape,name='coordinates')\n",
    "    inputs['coordinates']=cin\n",
    "\n",
    "    x,c = normalized_inputs,cin\n",
    "    \n",
    "    x,c = vgg_block(x,c, filters=start_filters,   ksize=3, l2_reg=l2_reg, n_convs=2, drop_rate=0.1)   # (60,120)\n",
    "    x,c = vgg_block(x,c, filters=2*start_filters, ksize=3, l2_reg=l2_reg, n_convs=2, drop_rate=0.1)  # (30,60)\n",
    "    x,c = vgg_block(x,c, filters=4*start_filters, ksize=3, l2_reg=l2_reg, n_convs=3, drop_rate=0.1)  # (15,30)\n",
    "    x,c = vgg_block(x,c, filters=8*start_filters, ksize=3, l2_reg=l2_reg, n_convs=3, drop_rate=0.1)  # (7,15)\n",
    "    #x,c = vgg_block(x,c, filters=8*start_filters, ksize=3, l2_reg=l2_reg, n_convs=3)  # (3,7)\n",
    "    \n",
    "    if head=='mlp':\n",
    "        # MLP head\n",
    "        x = keras.layers.Flatten()(x) \n",
    "        x = keras.layers.Dense(units = 4096, activation ='relu')(x) \n",
    "        x = keras.layers.Dense(units = 2024, activation ='relu')(x) \n",
    "        output = keras.layers.Dense(1)(x)\n",
    "    elif head=='maxpool':\n",
    "        # Per gridcell\n",
    "        x = keras.layers.Conv2D(filters=512, kernel_size=1,\n",
    "                          kernel_regularizer=keras.regularizers.l2(l2_reg),\n",
    "                          activation='relu')(x)\n",
    "        x = keras.layers.Conv2D(filters=256, kernel_size=1,\n",
    "                          kernel_regularizer=keras.regularizers.l2(l2_reg),\n",
    "                          activation='relu')(x)\n",
    "        x = keras.layers.Conv2D(filters=1, kernel_size=1,name='heatmap')(x)\n",
    "        # Max in scene\n",
    "        output = keras.layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "    return keras.Model(inputs=inputs,outputs=output)\n",
    "\n",
    "\n",
    "def vgg_block(x,c, filters=64, ksize=3, n_convs=2, l2_reg=1e-6, drop_rate=0.0):\n",
    "\n",
    "    for _ in range(n_convs):\n",
    "        x,c = CoordConv2D(filters=filters,\n",
    "                          kernel_size=ksize,\n",
    "                          kernel_regularizer=keras.regularizers.l2(l2_reg),\n",
    "                          padding='same',\n",
    "                          activation='relu')([x,c])\n",
    "    x = keras.layers.MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
    "    c = keras.layers.MaxPool2D(pool_size =2, strides =2, padding ='same')(c)\n",
    "    if drop_rate>0:\n",
    "        x = keras.layers.Dropout(rate=drop_rate)(x)\n",
    "    return x,c\n",
    "\n",
    "\n",
    "def normalize(x,\n",
    "              name:str):\n",
    "    \"\"\"\n",
    "    Channel-wise normalization using known CHANNEL_MIN_MAX\n",
    "    \"\"\"\n",
    "    min_max = np.array(CHANNEL_MIN_MAX[name]) # [2,]\n",
    "    n_sweeps=x.shape[-1]\n",
    "    \n",
    "    # choose mean,var to get approximate [-1,1] scaling\n",
    "    var=((min_max[1]-min_max[0])/2)**2 # scalar\n",
    "    var=np.array(n_sweeps*[var,])    # [n_sweeps,]\n",
    "    \n",
    "    offset=(min_max[0]+min_max[1])/2    # scalar\n",
    "    offset=np.array(n_sweeps*[offset,]) # [n_sweeps,]\n",
    "\n",
    "    return keras.layers.Normalization(mean=offset,\n",
    "                                      variance=var,\n",
    "                                      name='Normalize_%s' % name)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8144dffa-e578-423e-8e11-53b6fb6ce4cb",
   "metadata": {},
   "source": [
    "## Running the Model\n",
    "\n",
    "Ok, we've got all of the TorNet model components figured out and imported (using the helper functions, etc.).\n",
    "[Even getting that working turned out to be tricky - there were dependency issues to resolve, and while we'd \n",
    "like to just be able to import the functions rather than re-copying them here again, that wasn't working so well.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f9c3be5-ebd6-4c7c-83ac-bf8708944ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732231748.971067   23331 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5564 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37672757-38a1-4e97-a135-c527e7ae02a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ DBZ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ VEL (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ KDP (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ RHOHV (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ZDR (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ WIDTH (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Normalize_DBZ       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ DBZ[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Normalize_VEL       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ VEL[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Normalize_KDP       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ KDP[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Normalize_RHOHV     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ RHOHV[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Normalize_ZDR       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ZDR[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Normalize_WIDTH     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ WIDTH[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Concatenate1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Normalize_DBZ[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)               │            │ Normalize_VEL[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ Normalize_KDP[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ Normalize_RHOHV[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ Normalize_ZDR[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ Normalize_WIDTH[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ isnan (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Isnan</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Concatenate1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ where (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Where</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ isnan[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)               │            │ Concatenate1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ range_folded_mask   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Concatenate2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ where[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)               │            │ range_folded_mas… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coordinates         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d        │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,280</span> │ Concatenate2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CoordConv2D</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,  │            │ coordinates[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)]          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_1      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, │     <span style=\"color: #00af00; text-decoration-color: #00af00\">38,080</span> │ coord_conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CoordConv2D</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,  │            │ coord_conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)]          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ coord_conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ coord_conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_2      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">76,160</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CoordConv2D</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>,  │            │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)]          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_3      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">149,888</span> │ coord_conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CoordConv2D</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>,  │            │ coord_conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)]          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ coord_conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ coord_conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_4      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>,   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">299,776</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CoordConv2D</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,  │            │ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)]           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_5      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>,   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">594,688</span> │ coord_conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CoordConv2D</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,  │            │ coord_conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)]           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_6      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>,   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">594,688</span> │ coord_conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CoordConv2D</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,  │            │ coord_conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)]           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ coord_conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ coord_conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_7      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,189,376</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CoordConv2D</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>,  │            │ max_pooling2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)]           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_8      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,369,024</span> │ coord_conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CoordConv2D</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>,  │            │ coord_conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)]           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_9      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,369,024</span> │ coord_conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CoordConv2D</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>,  │            │ coord_conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)]           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ coord_conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ heatmap (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ heatmap[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling2…</span> │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ DBZ (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│                     │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ VEL (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│                     │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ KDP (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│                     │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ RHOHV (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│                     │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ZDR (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│                     │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ WIDTH (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│                     │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Normalize_DBZ       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ DBZ[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mNormalization\u001b[0m)     │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Normalize_VEL       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ VEL[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mNormalization\u001b[0m)     │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Normalize_KDP       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ KDP[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mNormalization\u001b[0m)     │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Normalize_RHOHV     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ RHOHV[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mNormalization\u001b[0m)     │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Normalize_ZDR       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ ZDR[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mNormalization\u001b[0m)     │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Normalize_WIDTH     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ WIDTH[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mNormalization\u001b[0m)     │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Concatenate1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ Normalize_DBZ[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m12\u001b[0m)               │            │ Normalize_VEL[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ Normalize_KDP[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ Normalize_RHOHV[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ Normalize_ZDR[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ Normalize_WIDTH[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ isnan (\u001b[38;5;33mIsnan\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ Concatenate1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m12\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ where (\u001b[38;5;33mWhere\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ isnan[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │ \u001b[38;5;34m12\u001b[0m)               │            │ Concatenate1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ range_folded_mask   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Concatenate2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ where[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m14\u001b[0m)               │            │ range_folded_mas… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coordinates         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d        │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m, │      \u001b[38;5;34m9,280\u001b[0m │ Concatenate2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mCoordConv2D\u001b[0m)       │ \u001b[38;5;34m64\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m,  │            │ coordinates[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m2\u001b[0m)]          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_1      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m, │     \u001b[38;5;34m38,080\u001b[0m │ coord_conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mCoordConv2D\u001b[0m)       │ \u001b[38;5;34m64\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m,  │            │ coord_conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m2\u001b[0m)]          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m120\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ coord_conv2d_1[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m120\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m120\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ coord_conv2d_1[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_2      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m120\u001b[0m,  │     \u001b[38;5;34m76,160\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mCoordConv2D\u001b[0m)       │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m,  │            │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m2\u001b[0m)]          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_3      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m120\u001b[0m,  │    \u001b[38;5;34m149,888\u001b[0m │ coord_conv2d_2[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mCoordConv2D\u001b[0m)       │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m,  │            │ coord_conv2d_2[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m2\u001b[0m)]          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m60\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ coord_conv2d_3[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m60\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m2\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ coord_conv2d_3[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_4      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m60\u001b[0m,   │    \u001b[38;5;34m299,776\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mCoordConv2D\u001b[0m)       │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m,  │            │ max_pooling2d_3[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m2\u001b[0m)]           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_5      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m60\u001b[0m,   │    \u001b[38;5;34m594,688\u001b[0m │ coord_conv2d_4[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mCoordConv2D\u001b[0m)       │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m,  │            │ coord_conv2d_4[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m2\u001b[0m)]           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_6      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m60\u001b[0m,   │    \u001b[38;5;34m594,688\u001b[0m │ coord_conv2d_5[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mCoordConv2D\u001b[0m)       │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m,  │            │ coord_conv2d_5[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m2\u001b[0m)]           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ coord_conv2d_6[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_4[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m2\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ coord_conv2d_6[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_7      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m30\u001b[0m,   │  \u001b[38;5;34m1,189,376\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mCoordConv2D\u001b[0m)       │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m,  │            │ max_pooling2d_5[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m2\u001b[0m)]           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_8      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m30\u001b[0m,   │  \u001b[38;5;34m2,369,024\u001b[0m │ coord_conv2d_7[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mCoordConv2D\u001b[0m)       │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m,  │            │ coord_conv2d_7[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m2\u001b[0m)]           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_9      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m30\u001b[0m,   │  \u001b[38;5;34m2,369,024\u001b[0m │ coord_conv2d_8[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mCoordConv2D\u001b[0m)       │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m,  │            │ coord_conv2d_8[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m2\u001b[0m)]           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m15\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ coord_conv2d_9[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m15\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_6[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m15\u001b[0m,     │    \u001b[38;5;34m262,656\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m15\u001b[0m,     │    \u001b[38;5;34m131,328\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ heatmap (\u001b[38;5;33mConv2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │        \u001b[38;5;34m257\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ heatmap[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling2…\u001b[0m │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,084,225</span> (30.84 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,084,225\u001b[0m (30.84 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,084,225</span> (30.84 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,084,225\u001b[0m (30.84 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1a005a-757f-4d9a-b4ca-e29426bdefad",
   "metadata": {},
   "source": [
    "Again, as mentioned above, of note here is the learning rate chosen, which is 10^-4.\n",
    "\n",
    "The original version of this notebook attempted to use 10^-3, but that caused the model to fail to converge after just one epoch of training (later epochs failed to make any progress). In comparison, using 10^-4 (while slower initially) seems to work well in training the data over the course of at least four epochs.\n",
    "\n",
    "As noted in the previous notebook, we might consider decaying the learning rate even further (due to our small batch size) later in this training for later epochs, because the small batch size can cause noisiness in gradient descent updates (so dampening those updates a bit can help the model converge). We'll monitor and see how that goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c56071c5-1a70-4a5b-8fc9-e736ebde6a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "loss = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "model.compile(loss=loss, optimizer=opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1381c59e-18b7-4b16-ac29-74d4b30ad806",
   "metadata": {},
   "source": [
    "We create a checkpoint saving function just to deal with iPython's many kernel crashes.\n",
    "After each pass through the data and all batches, we'll save the weights, reload the model, and keep going.\n",
    "\n",
    "We'll save the weights in `checkpoints/epoch_{number_of_epoch}.weights.h5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fea1e22b-bc9c-4ed7-807c-baa52e71d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint_creator(checkpoint_path):\n",
    "    # saving the model's weights in case the iPython kernel crashes (which it likes to do)\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                       save_weights_only=True,\n",
    "                                       verbose=1)\n",
    "    return cp_callback\n",
    "\n",
    "def checkpoint_loader(checkpoint_path, model):\n",
    "    model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2112eb5-6cd4-45fe-8d21-83ef2074fc4d",
   "metadata": {},
   "source": [
    "First pass through the data. Again, with each pass, we set it up with:\n",
    "- A batch_size of 64 (to fit the data into GPU memory)\n",
    "- Shuffle the data with a random_state (we pick a new seed each time, but record that seed here so we don't reuse it in a later epoch)\n",
    "- Set up a new checkpoint for each epoch (in case any one epoch of training crashes/fails)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25ddfa68-e121-4440-bacc-125c7f9f00fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = make_tf_with_flips_loader(data_root = TORNET_DATA_INPUT_FOLDER, \n",
    "                                         data_type = \"train\", # or 'test'\n",
    "                                         years = list(range(2013, 2023)),\n",
    "                                         batch_size = 64, \n",
    "                                         weights = None,\n",
    "                                         include_az = False,\n",
    "                                         random_state = 5678,\n",
    "                                         select_keys = ALL_VARIABLES + [\"coordinates\", \"range_folded_mask\"],\n",
    "                                         tilt_last = True,\n",
    "                                         from_tfds = False,\n",
    "                                         tfds_data_version =\"1.1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d79f207a-8752-4bc2-992b-054c1af63860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731973690.907013   17376 service.cc:148] XLA service 0x7f62f8019090 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1731973690.907543   17376 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2024-11-18 15:48:11.049961: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1731973691.398709   17376 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "E0000 00:00:1731973695.090274   17376 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "I0000 00:00:1731973715.098554   17376 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2867/Unknown \u001b[1m9308s\u001b[0m 3s/step - loss: 1.3145\n",
      "Epoch 1: saving model to checkpoints/epoch_flipping_1_1e-4.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 18:23:15.488076: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-11-18 18:23:15.490720: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_12]]\n",
      "2024-11-18 18:23:15.491729: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 18317437428072606055\n",
      "2024-11-18 18:23:15.491761: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 12506195242215264983\n",
      "2024-11-18 18:23:15.491768: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 944059850056747535\n",
      "2024-11-18 18:23:15.491772: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1264007328355077277\n",
      "2024-11-18 18:23:15.491958: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 4262657239284205003\n",
      "2024-11-18 18:23:15.492109: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14515781602841935606\n",
      "2024-11-18 18:23:15.492124: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 293195287202640562\n",
      "2024-11-18 18:23:15.492129: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 2149321471284453066\n",
      "2024-11-18 18:23:15.492173: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 6842426328757759826\n",
      "/usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2867/2867\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9310s\u001b[0m 3s/step - loss: 1.3143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f640bab3490>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(preprocessed, epochs=1, callbacks=[checkpoint_creator(\"checkpoints/epoch_flipping_1_1e-4.weights.h5\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da684670-9f21-4229-b50f-dcccc27b9342",
   "metadata": {},
   "source": [
    "Now we loop through a bunch of epochs to train the CNN further, making sure to change the random_state each time to mini-batch the data differently each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6e5125-b437-41f2-9111-3a285ece926a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2867/Unknown \u001b[1m9357s\u001b[0m 3s/step - loss: 0.3107\n",
      "Epoch 1: saving model to checkpoints/epoch_flipping_2_1e-4.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 23:22:16.192384: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_12]]\n",
      "2024-11-18 23:22:16.197645: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 18317437428072606055\n",
      "2024-11-18 23:22:16.197671: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 12506195242215264983\n",
      "2024-11-18 23:22:16.197679: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 944059850056747535\n",
      "2024-11-18 23:22:16.197684: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1264007328355077277\n",
      "2024-11-18 23:22:16.197716: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 4262657239284205003\n",
      "2024-11-18 23:22:16.197746: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14515781602841935606\n",
      "2024-11-18 23:22:16.197752: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 293195287202640562\n",
      "2024-11-18 23:22:16.197756: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 2149321471284453066\n",
      "2024-11-18 23:22:16.197794: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 6842426328757759826\n",
      "/usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2867/2867\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9359s\u001b[0m 3s/step - loss: 0.3107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 01:40:10.174991: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 117964864 bytes after encountering the first element of size 117964864 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3/Unknown \u001b[1m34s\u001b[0m 14s/step - loss: 0.2262"
     ]
    }
   ],
   "source": [
    "for epoch_num in range(2, 5):\n",
    "    resampled = make_tf_with_flips_loader(data_root = TORNET_DATA_INPUT_FOLDER, \n",
    "                                          data_type = \"train\", # or 'test'\n",
    "                                          years = list(range(2013, 2023)),\n",
    "                                          batch_size = 64, \n",
    "                                          weights = None,\n",
    "                                          include_az = False,\n",
    "                                          random_state = 1234 + epoch_num,\n",
    "                                          select_keys = ALL_VARIABLES + [\"coordinates\", \"range_folded_mask\"],\n",
    "                                          tilt_last = True,\n",
    "                                          from_tfds = False,\n",
    "                                          tfds_data_version =\"1.1.0\")\n",
    "    checkpoint_loader(\"checkpoints/epoch_flipping_{}_1e-4.weights.h5\".format(str(epoch_num - 1)), model)\n",
    "    model.fit(resampled, epochs=1, callbacks=[checkpoint_creator(\"checkpoints/epoch_flipping_{}_1e-4.weights.h5\".format(epoch_num))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fcb6332-6578-4146-830b-73013695004c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 54 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732045742.183686   21628 service.cc:148] XLA service 0x7f6628018f50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732045742.184072   21628 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2024-11-19 11:49:02.310836: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1732045742.629618   21628 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1732045765.958023   21628 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2867/Unknown \u001b[1m9839s\u001b[0m 3s/step - loss: 0.2538\n",
      "Epoch 1: saving model to checkpoints/epoch_flipping_3_1e-4.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 14:32:58.471917: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-11-19 14:32:58.472487: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_18]]\n",
      "2024-11-19 14:32:58.472792: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 18125960373766345697\n",
      "2024-11-19 14:32:58.472815: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 9072318686438974239\n",
      "2024-11-19 14:32:58.472821: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1040842881928324157\n",
      "2024-11-19 14:32:58.472825: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1237740458513806647\n",
      "2024-11-19 14:32:58.472829: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 12632295518641251943\n",
      "2024-11-19 14:32:58.472834: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 9048254918056089224\n",
      "2024-11-19 14:32:58.472836: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1534801658280426416\n",
      "2024-11-19 14:32:58.472839: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 18221563437090840100\n",
      "2024-11-19 14:32:58.472873: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 12621612113631110748\n",
      "/usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2867/2867\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9842s\u001b[0m 3s/step - loss: 0.2538\n",
      "   2867/Unknown \u001b[1m11148s\u001b[0m 4s/step - loss: 0.2376\n",
      "Epoch 1: saving model to checkpoints/epoch_flipping_4_1e-4.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 19:56:04.202585: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_18]]\n",
      "/usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "2024-11-19 19:56:04.206253: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 18125960373766345697\n",
      "2024-11-19 19:56:04.206311: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 9072318686438974239\n",
      "2024-11-19 19:56:04.206324: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1040842881928324157\n",
      "2024-11-19 19:56:04.206328: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1237740458513806647\n",
      "2024-11-19 19:56:04.206332: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 12632295518641251943\n",
      "2024-11-19 19:56:04.206356: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 9048254918056089224\n",
      "2024-11-19 19:56:04.206361: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1534801658280426416\n",
      "2024-11-19 19:56:04.206364: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 18221563437090840100\n",
      "2024-11-19 19:56:04.206389: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 12621612113631110748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2867/2867\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11151s\u001b[0m 4s/step - loss: 0.2376\n"
     ]
    }
   ],
   "source": [
    "for epoch_num in range(3, 5):\n",
    "    resampled = make_tf_with_flips_loader(data_root = TORNET_DATA_INPUT_FOLDER, \n",
    "                                          data_type = \"train\", # or 'test'\n",
    "                                          years = list(range(2013, 2023)),\n",
    "                                          batch_size = 64, \n",
    "                                          weights = None,\n",
    "                                          include_az = False,\n",
    "                                          random_state = 1234 + epoch_num,\n",
    "                                          select_keys = ALL_VARIABLES + [\"coordinates\", \"range_folded_mask\"],\n",
    "                                          tilt_last = True,\n",
    "                                          from_tfds = False,\n",
    "                                          tfds_data_version =\"1.1.0\")\n",
    "    checkpoint_loader(\"checkpoints/epoch_flipping_{}_1e-4.weights.h5\".format(str(epoch_num - 1)), model)\n",
    "    model.fit(resampled, epochs=1, callbacks=[checkpoint_creator(\"checkpoints/epoch_flipping_{}_1e-4.weights.h5\".format(epoch_num))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7273478-035d-4ef9-809d-31389e6eebef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_num in range(5, 7):\n",
    "    resampled = make_tf_with_flips_loader(data_root = TORNET_DATA_INPUT_FOLDER, \n",
    "                                          data_type = \"train\", # or 'test'\n",
    "                                          years = list(range(2013, 2023)),\n",
    "                                          batch_size = 64, \n",
    "                                          weights = None,\n",
    "                                          include_az = False,\n",
    "                                          random_state = 1234 + epoch_num,\n",
    "                                          select_keys = ALL_VARIABLES + [\"coordinates\", \"range_folded_mask\"],\n",
    "                                          tilt_last = True,\n",
    "                                          from_tfds = False,\n",
    "                                          tfds_data_version =\"1.1.0\")\n",
    "    checkpoint_loader(\"checkpoints/epoch_flipping_{}_1e-4.weights.h5\".format(str(epoch_num - 1)), model)\n",
    "    model.fit(resampled, epochs=1, callbacks=[checkpoint_creator(\"checkpoints/epoch_flipping_{}_1e-4.weights.h5\".format(epoch_num))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fda516-715f-4019-98e6-abaafc4914c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 54 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2867/Unknown \u001b[1m9105s\u001b[0m 3s/step - loss: 0.2140\n",
      "Epoch 1: saving model to checkpoints/epoch_flipping_7_1e-4.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 20:50:42.094627: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_8]]\n",
      "2024-11-20 20:50:42.097826: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 11792009927715927949\n",
      "2024-11-20 20:50:42.097844: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 10503351137423630075\n",
      "2024-11-20 20:50:42.097849: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 8873016923517038427\n",
      "2024-11-20 20:50:42.097855: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1358983975771822302\n",
      "2024-11-20 20:50:42.097859: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5465932250389205152\n",
      "2024-11-20 20:50:42.097862: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 3497044298265619036\n",
      "2024-11-20 20:50:42.097865: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 12000807716464649026\n",
      "2024-11-20 20:50:42.097867: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14565796626948094974\n",
      "2024-11-20 20:50:42.097897: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 6796921093029644112\n",
      "/usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2867/2867\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9107s\u001b[0m 3s/step - loss: 0.2140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 23:03:57.895288: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 117964864 bytes after encountering the first element of size 117964864 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4/Unknown \u001b[1m18s\u001b[0m 4s/step - loss: 0.1937"
     ]
    }
   ],
   "source": [
    "for epoch_num in range(7, 8):\n",
    "    resampled = make_tf_with_flips_loader(data_root = TORNET_DATA_INPUT_FOLDER, \n",
    "                                          data_type = \"train\", # or 'test'\n",
    "                                          years = list(range(2013, 2023)),\n",
    "                                          batch_size = 64, \n",
    "                                          weights = None,\n",
    "                                          include_az = False,\n",
    "                                          random_state = 1234 + epoch_num,\n",
    "                                          select_keys = ALL_VARIABLES + [\"coordinates\", \"range_folded_mask\"],\n",
    "                                          tilt_last = True,\n",
    "                                          from_tfds = False,\n",
    "                                          tfds_data_version =\"1.1.0\")\n",
    "    checkpoint_loader(\"checkpoints/epoch_flipping_{}_1e-4.weights.h5\".format(str(epoch_num - 1)), model)\n",
    "    model.fit(resampled, epochs=1, callbacks=[checkpoint_creator(\"checkpoints/epoch_flipping_{}_1e-4.weights.h5\".format(epoch_num))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1ac9482-dfbb-4103-972d-0be373ac1c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 54 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732181742.860156   15124 service.cc:148] XLA service 0x7f3e9c018eb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732181742.860471   15124 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2024-11-21 01:35:42.973705: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1732181743.275769   15124 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "E0000 00:00:1732181745.413249   15124 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "I0000 00:00:1732181766.645622   15124 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2867/Unknown \u001b[1m9033s\u001b[0m 3s/step - loss: 0.2079\n",
      "Epoch 1: saving model to checkpoints/epoch_flipping_8_1e-4.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 04:06:12.691764: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-11-21 04:06:12.691856: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_10]]\n",
      "2024-11-21 04:06:12.691868: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 12827997819925368895\n",
      "2024-11-21 04:06:12.691871: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 10259843889643680281\n",
      "2024-11-21 04:06:12.691876: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 2283971990208613307\n",
      "2024-11-21 04:06:12.691879: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 65729284537371621\n",
      "2024-11-21 04:06:12.691885: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 4687782750711658532\n",
      "2024-11-21 04:06:12.691887: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 9391880592736711200\n",
      "2024-11-21 04:06:12.691890: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5774203960222149612\n",
      "2024-11-21 04:06:12.691894: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 391584738457161164\n",
      "2024-11-21 04:06:12.691918: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 590530956098035478\n",
      "/usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2867/2867\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9035s\u001b[0m 3s/step - loss: 0.2079\n"
     ]
    }
   ],
   "source": [
    "for epoch_num in range(8, 9):\n",
    "    resampled = make_tf_with_flips_loader(data_root = TORNET_DATA_INPUT_FOLDER, \n",
    "                                          data_type = \"train\", # or 'test'\n",
    "                                          years = list(range(2013, 2023)),\n",
    "                                          batch_size = 64, \n",
    "                                          weights = None,\n",
    "                                          include_az = False,\n",
    "                                          random_state = 1234 + epoch_num,\n",
    "                                          select_keys = ALL_VARIABLES + [\"coordinates\", \"range_folded_mask\"],\n",
    "                                          tilt_last = True,\n",
    "                                          from_tfds = False,\n",
    "                                          tfds_data_version =\"1.1.0\")\n",
    "    checkpoint_loader(\"checkpoints/epoch_flipping_{}_1e-4.weights.h5\".format(str(epoch_num - 1)), model)\n",
    "    model.fit(resampled, epochs=1, callbacks=[checkpoint_creator(\"checkpoints/epoch_flipping_{}_1e-4.weights.h5\".format(epoch_num))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "805c8e95-dbf4-4c52-94e5-b217e00141a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 54 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2867/Unknown \u001b[1m14114s\u001b[0m 5s/step - loss: 0.1976"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 15:08:15.938919: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_10]]\n",
      "2024-11-21 15:08:15.942789: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 12827997819925368895\n",
      "2024-11-21 15:08:15.942815: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 10259843889643680281\n",
      "2024-11-21 15:08:15.942823: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 2283971990208613307\n",
      "2024-11-21 15:08:15.942828: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 65729284537371621\n",
      "2024-11-21 15:08:15.942839: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 4687782750711658532\n",
      "2024-11-21 15:08:15.942843: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 9391880592736711200\n",
      "2024-11-21 15:08:15.942847: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5774203960222149612\n",
      "2024-11-21 15:08:15.942850: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 391584738457161164\n",
      "2024-11-21 15:08:15.942898: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 590530956098035478\n",
      "/usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to checkpoints/epoch_flipping_9_1e-4.weights.h5\n",
      "\u001b[1m2867/2867\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14135s\u001b[0m 5s/step - loss: 0.1976\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=5e-5)\n",
    "loss = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "model.compile(loss=loss, optimizer=opt)\n",
    "\n",
    "for epoch_num in range(9, 10):\n",
    "    resampled = make_tf_with_flips_loader(data_root = TORNET_DATA_INPUT_FOLDER, \n",
    "                                          data_type = \"train\", # or 'test'\n",
    "                                          years = list(range(2013, 2023)),\n",
    "                                          batch_size = 64, \n",
    "                                          weights = None,\n",
    "                                          include_az = False,\n",
    "                                          random_state = 1234 + epoch_num,\n",
    "                                          select_keys = ALL_VARIABLES + [\"coordinates\", \"range_folded_mask\"],\n",
    "                                          tilt_last = True,\n",
    "                                          from_tfds = False,\n",
    "                                          tfds_data_version =\"1.1.0\")\n",
    "    checkpoint_loader(\"checkpoints/epoch_flipping_{}_1e-4.weights.h5\".format(str(epoch_num - 1)), model)\n",
    "    model.fit(resampled, epochs=1, callbacks=[checkpoint_creator(\"checkpoints/epoch_flipping_{}_1e-4.weights.h5\".format(epoch_num))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fb03ba-5628-4248-8e5d-1e6a31423265",
   "metadata": {},
   "source": [
    "## Testing on test data\n",
    "\n",
    "In our test data, we DON'T want to do any flipping or data augmentation. So, before we run the test data \n",
    "evaluation, we have to bring back TorNet's original functions for loading the test data into a \n",
    "Tensorflow dataset.\n",
    "\n",
    "After we do that, we can run through the testing data for each epoch to see how the model performed\n",
    "after each epoch of training in terms of AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d5925fa-1c91-4ec1-b5b7-e24f87d23843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset(files:str,\n",
    "                      variables: List[str]=ALL_VARIABLES,\n",
    "                      n_frames:int=1,\n",
    "                      tilt_last: bool=True) -> tf.data.Dataset:\n",
    "    \"\"\"\n",
    "    This is Tornet's main function for loading the data from the folder where it's all stored.\n",
    "    \n",
    "    As they stated, this creates a TF dataset object via the function read_file (which reads the NetCDF files\n",
    "    into the data one at a time).\n",
    "    \"\"\"\n",
    "    assert len(files)>0\n",
    "    # grab one file to gets keys, shapes, etc\n",
    "    data = read_file(files[0],variables=variables,n_frames=n_frames, tilt_last=tilt_last)\n",
    "    \n",
    "    output_signature = { k:tf.TensorSpec(shape=data[k].shape,dtype=data[k].dtype,name=k) for k in data }\n",
    "    def gen():\n",
    "        for f in files:\n",
    "            yield read_file(f,variables=variables,n_frames=n_frames, tilt_last=tilt_last)\n",
    "    ds = tf.data.Dataset.from_generator(gen,\n",
    "                                        output_signature=output_signature)\n",
    "    return ds\n",
    "\n",
    "def make_tf_loader(data_root: str, \n",
    "            data_type:str='train', # or 'test'\n",
    "            years: list=list(range(2013,2023)),\n",
    "            batch_size: int=128, \n",
    "            weights: Dict=None,\n",
    "            include_az: bool=False,\n",
    "            random_state:int=1234,\n",
    "            select_keys: list=None,\n",
    "            tilt_last: bool=True,\n",
    "            from_tfds: bool=False,\n",
    "            tfds_data_version: str='1.1.0',\n",
    "            num_epochs: int=3):\n",
    "    \"\"\"\n",
    "    This TorNet library function is used to load the data into Tensorflow.\n",
    "    We're going to use the `create_tf_dataset` function from above, \n",
    "    then we'll use `preproc` to preprocess it.\n",
    "\n",
    "    One important note - we tried a bunch of different functions for shuffling \n",
    "    and batching, repeating the dataset, etc. to try to be able to run\n",
    "    many epochs with one function call. It wasn't working.\n",
    "    Even the `drop_remainder=True` that we've added here to ds.batch\n",
    "    seems to not really have an effect, as the model training\n",
    "    still throws an error at the end of training about running out of data.\n",
    "    \"\"\"\n",
    "    \n",
    "    if from_tfds: # fast loader\n",
    "        import tensorflow_datasets as tfds\n",
    "        import tornet.data.tfds.tornet.tornet_dataset_builder # registers 'tornet'\n",
    "        ds = tfds.load('tornet:%s' % tfds_data_version ,split='+'.join(['%s-%d' % (data_type,y) for y in years]))\n",
    "        # Assumes data was saved with tilt_last=True and converts it to tilt_last=False\n",
    "        if not tilt_last:\n",
    "            ds = ds.map(lambda d: pp.permute_dims(d,(0,3,1,2), backend=tf))\n",
    "    else: # Load directly from netcdf files\n",
    "        file_list = query_catalog(data_root, data_type, years, random_state)\n",
    "        ds = create_tf_dataset(file_list,variables=ALL_VARIABLES,n_frames=1, tilt_last=tilt_last) \n",
    "\n",
    "    ds = preproc(ds,weights,include_az,select_keys,tilt_last)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # this has been adjusted to include drop_remainder=True\n",
    "    ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83a410b-d4c1-4179-8bef-a48d523191a5",
   "metadata": {},
   "source": [
    "For each epoch that we trained through, let's test the model and see how it did after each pass of the data.\n",
    "AUC is our evaluation metric here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5bed535-c6bc-48b3-a510-3a0db1369894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 54 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732079977.799323     856 service.cc:148] XLA service 0x7ff4a800db50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732079977.799664     856 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2024-11-19 21:19:37.834266: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1732079977.932640     856 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2/Unknown \u001b[1m13s\u001b[0m 67ms/step - AUC: 0.4362 - loss: 0.1598   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732079986.378947     856 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1590s\u001b[0m 3s/step - AUC: 0.8184 - loss: 0.2154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 21:46:03.694408: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-11-19 21:46:03.694462: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_14]]\n",
      "2024-11-19 21:46:03.694472: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 12744976677381798467\n",
      "2024-11-19 21:46:03.694475: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 9096861446359773735\n",
      "2024-11-19 21:46:03.694479: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5502915226632464905\n",
      "2024-11-19 21:46:03.694482: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 8169583992736786955\n",
      "2024-11-19 21:46:03.694485: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 17117769626377841927\n",
      "2024-11-19 21:46:03.694488: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 992421454627991131\n",
      "2024-11-19 21:46:03.694490: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 9799722824554614607\n",
      "2024-11-19 21:46:03.694494: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 8612676659198615726\n",
      "2024-11-19 21:46:03.694513: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 11735222185637296740\n",
      "/usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "/usr/local/lib/python3.9/dist-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 54 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1668s\u001b[0m 3s/step - AUC: 0.8388 - loss: 0.2028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 22:13:52.101356: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_14]]\n",
      "/usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "2024-11-19 22:13:52.101397: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 9799722824554614607\n",
      "2024-11-19 22:13:52.101403: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 9096861446359773735\n",
      "2024-11-19 22:13:52.101407: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 8169583992736786955\n",
      "2024-11-19 22:13:52.101410: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5502915226632464905\n",
      "2024-11-19 22:13:52.101413: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 12744976677381798467\n",
      "2024-11-19 22:13:52.101416: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 17117769626377841927\n",
      "2024-11-19 22:13:52.101419: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 992421454627991131\n",
      "2024-11-19 22:13:52.101425: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 8612676659198615726\n",
      "2024-11-19 22:13:52.101442: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 11735222185637296740\n"
     ]
    }
   ],
   "source": [
    "test_data = make_tf_loader(data_root = TORNET_DATA_INPUT_FOLDER, \n",
    "                              data_type = \"test\",\n",
    "                              years = list(range(2013, 2023)),\n",
    "                              batch_size = 64, \n",
    "                              weights = None,\n",
    "                              include_az = False,\n",
    "                              random_state = 5678,\n",
    "                              select_keys = ALL_VARIABLES + [\"coordinates\", \"range_folded_mask\"],\n",
    "                              tilt_last = True,\n",
    "                              from_tfds = False,\n",
    "                              tfds_data_version =\"1.1.0\")\n",
    "\n",
    "for epoch_num in range(3, 5):\n",
    "    metrics = [keras.metrics.AUC(from_logits=True,name='AUC')]\n",
    "    checkpoint_loader(\"checkpoints/epoch_flipping_{}_1e-4.weights.h5\".format(str(epoch_num)), model)\n",
    "    model.compile(loss=loss, metrics=metrics)\n",
    "    model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6beef51-759a-44aa-900d-41eac512f31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 54 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732135689.176521    4987 service.cc:148] XLA service 0x7fae94003af0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732135689.176917    4987 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2024-11-20 12:48:09.210472: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1732135689.302695    4987 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2/Unknown \u001b[1m13s\u001b[0m 74ms/step - AUC: 0.4285 - loss: 0.1316   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732135697.837069    4987 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1533s\u001b[0m 3s/step - AUC: 0.8609 - loss: 0.1914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 13:13:38.874242: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-11-20 13:13:38.874306: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_8]]\n",
      "2024-11-20 13:13:38.874324: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 8873016923517038427\n",
      "2024-11-20 13:13:38.874329: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 10503351137423630075\n",
      "2024-11-20 13:13:38.874334: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 11792009927715927949\n",
      "2024-11-20 13:13:38.874339: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1358983975771822302\n",
      "2024-11-20 13:13:38.874342: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5465932250389205152\n",
      "2024-11-20 13:13:38.874345: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 3497044298265619036\n",
      "2024-11-20 13:13:38.874349: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14565796626948094974\n",
      "2024-11-20 13:13:38.874351: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 12000807716464649026\n",
      "2024-11-20 13:13:38.874371: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 6796921093029644112\n",
      "/usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'checkpoints/epoch_flipping_7_1e-4.weights.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m8\u001b[39m):\n\u001b[1;32m     14\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m [keras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mAUC(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUC\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m---> 15\u001b[0m     \u001b[43mcheckpoint_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcheckpoints/epoch_flipping_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_1e-4.weights.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_num\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mloss, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n\u001b[1;32m     17\u001b[0m     model\u001b[38;5;241m.\u001b[39mevaluate(test_data)\n",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m, in \u001b[0;36mcheckpoint_loader\u001b[0;34m(checkpoint_path, model)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheckpoint_loader\u001b[39m(checkpoint_path, model):\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/h5py/_hl/files.py:561\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    552\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    553\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    554\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    555\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    556\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    557\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    558\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    559\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    560\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 561\u001b[0m     fid \u001b[38;5;241m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[38;5;241m=\u001b[39mswmr)\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'checkpoints/epoch_flipping_7_1e-4.weights.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "test_data = make_tf_loader(data_root = TORNET_DATA_INPUT_FOLDER, \n",
    "                              data_type = \"test\",\n",
    "                              years = list(range(2013, 2023)),\n",
    "                              batch_size = 64, \n",
    "                              weights = None,\n",
    "                              include_az = False,\n",
    "                              random_state = 5678,\n",
    "                              select_keys = ALL_VARIABLES + [\"coordinates\", \"range_folded_mask\"],\n",
    "                              tilt_last = True,\n",
    "                              from_tfds = False,\n",
    "                              tfds_data_version =\"1.1.0\")\n",
    "\n",
    "for epoch_num in range(6, 8):\n",
    "    metrics = [keras.metrics.AUC(from_logits=True,name='AUC')]\n",
    "    checkpoint_loader(\"checkpoints/epoch_flipping_{}_1e-4.weights.h5\".format(str(epoch_num)), model)\n",
    "    model.compile(loss=loss, metrics=metrics)\n",
    "    model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b23d658c-f74c-4691-b8ab-871464321593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1607s\u001b[0m 3s/step - AUC: 0.8659 - loss: 0.1903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 08:35:31.749291: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_10]]\n",
      "2024-11-21 08:35:31.750965: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 12827997819925368895\n",
      "2024-11-21 08:35:31.750981: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 10259843889643680281\n",
      "2024-11-21 08:35:31.750989: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 2283971990208613307\n",
      "2024-11-21 08:35:31.750994: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 65729284537371621\n",
      "2024-11-21 08:35:31.751002: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 4687782750711658532\n",
      "2024-11-21 08:35:31.751006: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 9391880592736711200\n",
      "2024-11-21 08:35:31.751010: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5774203960222149612\n",
      "2024-11-21 08:35:31.751015: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 391584738457161164\n",
      "2024-11-21 08:35:31.751036: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 590530956098035478\n",
      "/usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "/usr/local/lib/python3.9/dist-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 54 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1610s\u001b[0m 3s/step - AUC: 0.8663 - loss: 0.1890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 09:02:22.190477: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 12827997819925368895\n",
      "/usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "2024-11-21 09:02:22.190519: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 10259843889643680281\n",
      "2024-11-21 09:02:22.190526: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 2283971990208613307\n",
      "2024-11-21 09:02:22.190532: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 65729284537371621\n",
      "2024-11-21 09:02:22.190539: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 4687782750711658532\n",
      "2024-11-21 09:02:22.190545: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 9391880592736711200\n",
      "2024-11-21 09:02:22.190549: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5774203960222149612\n",
      "2024-11-21 09:02:22.190553: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 391584738457161164\n",
      "2024-11-21 09:02:22.190574: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 590530956098035478\n"
     ]
    }
   ],
   "source": [
    "test_data = make_tf_loader(data_root = TORNET_DATA_INPUT_FOLDER, \n",
    "                              data_type = \"test\",\n",
    "                              years = list(range(2013, 2023)),\n",
    "                              batch_size = 64, \n",
    "                              weights = None,\n",
    "                              include_az = False,\n",
    "                              random_state = 5678,\n",
    "                              select_keys = ALL_VARIABLES + [\"coordinates\", \"range_folded_mask\"],\n",
    "                              tilt_last = True,\n",
    "                              from_tfds = False,\n",
    "                              tfds_data_version =\"1.1.0\")\n",
    "\n",
    "for epoch_num in range(7, 9):\n",
    "    metrics = [keras.metrics.AUC(from_logits=True,name='AUC')]\n",
    "    checkpoint_loader(\"checkpoints/epoch_flipping_{}_1e-4.weights.h5\".format(str(epoch_num)), model)\n",
    "    model.compile(loss=loss, metrics=metrics)\n",
    "    model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d837a5f-6755-4a69-bf33-59c0ca3857c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 54 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732231767.728496   23418 service.cc:148] XLA service 0x7fce5000d3c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732231767.729281   23418 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2024-11-21 15:29:27.773098: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1732231767.896476   23418 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2/Unknown \u001b[1m11s\u001b[0m 65ms/step - AUC: 0.4374 - loss: 0.1248   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732231774.914547   23418 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1546s\u001b[0m 3s/step - AUC: 0.8804 - loss: 0.1836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 15:55:09.686421: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-11-21 15:55:09.686505: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_14]]\n",
      "2024-11-21 15:55:09.686522: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 13487443787624175879\n",
      "2024-11-21 15:55:09.686527: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 6682284121449466355\n",
      "2024-11-21 15:55:09.686532: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 6907914624901376875\n",
      "2024-11-21 15:55:09.686535: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 17021916078633971215\n",
      "2024-11-21 15:55:09.686538: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 16962612165641987899\n",
      "2024-11-21 15:55:09.686542: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 12872416329011749254\n",
      "2024-11-21 15:55:09.686546: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 2794086980411018186\n",
      "2024-11-21 15:55:09.686549: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 15686286726541339666\n",
      "2024-11-21 15:55:09.686570: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 3241818016139244394\n",
      "/usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    }
   ],
   "source": [
    "test_data = make_tf_loader(data_root = TORNET_DATA_INPUT_FOLDER, \n",
    "                              data_type = \"test\",\n",
    "                              years = list(range(2013, 2023)),\n",
    "                              batch_size = 64, \n",
    "                              weights = None,\n",
    "                              include_az = False,\n",
    "                              random_state = 5678,\n",
    "                              select_keys = ALL_VARIABLES + [\"coordinates\", \"range_folded_mask\"],\n",
    "                              tilt_last = True,\n",
    "                              from_tfds = False,\n",
    "                              tfds_data_version =\"1.1.0\")\n",
    "\n",
    "for epoch_num in range(9, 10):\n",
    "    metrics = [keras.metrics.AUC(from_logits=True,name='AUC')]\n",
    "    checkpoint_loader(\"checkpoints/epoch_flipping_{}_1e-4.weights.h5\".format(str(epoch_num)), model)\n",
    "    model.compile(loss=loss, metrics=metrics)\n",
    "    model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb89eba-8f04-41f6-af85-4821a9a2e830",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
