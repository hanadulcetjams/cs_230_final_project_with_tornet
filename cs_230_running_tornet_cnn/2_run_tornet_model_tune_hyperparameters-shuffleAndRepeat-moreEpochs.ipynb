{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b99b3ba1-a966-4502-857f-ef0344d141be",
   "metadata": {},
   "source": [
    "# Running the TorNet model\n",
    "\n",
    "The TorNet paper gave us a pretty good indicator of how to set up their baseline CNN model with CoordConv and VGG blocks.\n",
    "But even better, their actual TorNet repository gave us the actual model blocks themselves.\n",
    "\n",
    "Unfortunately, running their model out of the box with default settings does NOT perform as anticipated. \n",
    "The reasons for this were as follows:\n",
    "- Trying to run with a batch size of 128 was too large for the GPU we use here.\n",
    "    - We had to adjust the batch size until it would fit in memory - a good size turned out to be 64.\n",
    "- Using a learning rate (as demonstrated in their \"how to train the model\" examples) of 1e-3 also was too large, even with an Adam optimization algorithm.\n",
    "    - The paper doesn't list any learning rate in particular - it only states that hyperparameters were found using a grid search.\n",
    "    - After several trials and errors (searching on a log scale between 1e-3 and 1e-6), we found that around 1e-3 seemed to work reasonably.\n",
    "- In the paper, we were supposed to run at least around 3 epochs to start seeing reasonable performance. However, the iPython kernel kept dying in spite of the GPU being fine and healthy on each run (even after a single epoch).\n",
    "    - If we try to run more epochs using .repeat() (with shuffling, etc.), the iPython kernel crashes without fail.\n",
    "        - It's unclear why this occurs. In theory, even if the dataset \"runs out of data\" the model should just stop training, save the existing state, and continue...but that hasn't been the case so far. For some reason, the \"run out of data\" exception seems to kill the kernel from time to time.\n",
    "    - The only successful strategy (so far) has been the following:\n",
    "        - For each epoch:\n",
    "            - Reshuffle the data into a new TF dataset \n",
    "            - Batch the dataset into `batch_size`-sized batches\n",
    "                - In this case, we'd have 2,682 batches with 64 training examples each.\n",
    "                - Notably, even with `drop_remainder = True` Tensorflow still seems to complain about running out of data for a single epoch.\n",
    "            - Run a single epoch on that dataset\n",
    "            - Save the checkpoint from the model immediately (in case of iPython kernel crash)\n",
    "    - If the kernel ever crashes, we can then recover from the model checkpoint that we've saved weights to.\n",
    "\n",
    "Using the fixes, modifications, and adjustments above, we're going to try to reproduce the performance of the original model from TorNet (to within a reasonable degree) to show that their methodology does indeed result in a model with good predictive power [which we then hope to improve on]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "052ae79f-b46e-47ec-b29d-4538a9233d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 10:46:04.823945: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-15 10:46:05.007354: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731696365.123059    2159 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731696365.157377    2159 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-15 10:46:05.353461: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# just the location for the input data\n",
    "TORNET_DATA_INPUT_FOLDER = \"/mnt/c/users/handypark/Documents/Grad_School_Courses/CS_230/tornet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e4063f0-8bf4-48f6-ad78-b602b3216db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngpus = tf.config.list_physical_devices(\\'GPU\\')\\nif gpus:\\n  try:\\n    # Currently, memory growth needs to be the same across GPUs\\n    for gpu in gpus:\\n      tf.config.experimental.set_memory_growth(gpu, True)\\n    logical_gpus = tf.config.list_logical_devices(\\'GPU\\')\\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\\n  except RuntimeError as e:\\n    # Memory growth must be set before GPUs have been initialized\\n    print(e)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just making sure that we are indeed using GPU-based Tensorflow and not CPU-based Tensorflow.\n",
    "tf.test.is_built_with_cuda()\n",
    "\n",
    "# We tried experimental memory growth in some cases, but it didn't work out well (also crashed a lot).\n",
    "\"\"\"\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677cb397-68c6-47a7-8a18-577995858d9e",
   "metadata": {},
   "source": [
    "## TorNet's helper functions\n",
    "\n",
    "Included below are the main TorNet helper functions we use to create the dataset when loading it into Tensorflow.\n",
    "There weren't many changes here - these are mostly as is from the tornet repo.\n",
    "They are annotated with new comments to show how they will be used later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59daf357-3d58-45a9-a8fd-4f8062907a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TorNet's data loading code, re-imported here manually for loading data into TensorFlow.\n",
    "For some reason, trying to import the data loading code using `from tornet.data.tf.loader` wasn't working as expected,\n",
    "so we re-copy that code over here to make use of it.\n",
    "\"\"\"\n",
    "from typing import List, Dict\n",
    "\n",
    "from tornet.data.loader import query_catalog, read_file\n",
    "from tornet.data.constants import ALL_VARIABLES\n",
    "from tornet.data import preprocess as pp\n",
    "\n",
    "def create_tf_dataset(files:str,\n",
    "                      variables: List[str]=ALL_VARIABLES,\n",
    "                      n_frames:int=1,\n",
    "                      tilt_last: bool=True) -> tf.data.Dataset:\n",
    "    \"\"\"\n",
    "    This is Tornet's main function for loading the data from the folder where it's all stored.\n",
    "    \n",
    "    As they stated, this creates a TF dataset object via the function read_file (which reads the NetCDF files\n",
    "    into the data one at a time).\n",
    "    \"\"\"\n",
    "    assert len(files)>0\n",
    "    # grab one file to gets keys, shapes, etc\n",
    "    data = read_file(files[0],variables=variables,n_frames=n_frames, tilt_last=tilt_last)\n",
    "    \n",
    "    output_signature = { k:tf.TensorSpec(shape=data[k].shape,dtype=data[k].dtype,name=k) for k in data }\n",
    "    def gen():\n",
    "        for f in files:\n",
    "            yield read_file(f,variables=variables,n_frames=n_frames, tilt_last=tilt_last)\n",
    "    ds = tf.data.Dataset.from_generator(gen,\n",
    "                                        output_signature=output_signature)\n",
    "    return ds\n",
    "    \n",
    "\n",
    "def preproc(ds: tf.data.Dataset,\n",
    "            weights:Dict=None,\n",
    "            include_az:bool=False,\n",
    "            select_keys:list=None,\n",
    "            tilt_last:bool=True):\n",
    "    \"\"\"\n",
    "    This is Tornet's preprocessing function for taking the raw dataset loaded from the files (in create_tf_dataset)\n",
    "    and then doing a few things:\n",
    "\n",
    "    - Remove the time dimension (since we only care about detection at a given time t)\n",
    "    - Add coordinates (so that we can run CoordConv layers later)\n",
    "    - Split the data into its inputs and label outputs\n",
    "    - Adding weights (if we decide to weight the data at all)\n",
    "\n",
    "    Once the preprocessing is done, the data is basically ready to be trained on.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove time dimesnion\n",
    "    ds = ds.map(pp.remove_time_dim)\n",
    "\n",
    "    # Add coordinate tensors\n",
    "    ds = ds.map(lambda d: pp.add_coordinates(d,include_az=include_az,tilt_last=tilt_last,backend=tf))\n",
    "\n",
    "    # split into X,y\n",
    "    ds = ds.map(pp.split_x_y)\n",
    "\n",
    "    # Add sample weights\n",
    "    if weights:\n",
    "        ds = ds.map(lambda x,y:  pp.compute_sample_weight(x,y,**weights, backend=tf) )\n",
    "    \n",
    "        # select keys for input\n",
    "        if select_keys is not None:\n",
    "            ds = ds.map(lambda x,y,w: (pp.select_keys(x,keys=select_keys),y,w))\n",
    "    else:\n",
    "        if select_keys is not None:\n",
    "            ds = ds.map(lambda x,y: (pp.select_keys(x,keys=select_keys),y))\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57fd9150-7c8c-4cea-bd85-4b862ad28639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tf_loader(data_root: str, \n",
    "            data_type:str='train', # or 'test'\n",
    "            years: list=list(range(2013,2023)),\n",
    "            batch_size: int=128, \n",
    "            weights: Dict=None,\n",
    "            include_az: bool=False,\n",
    "            random_state:int=1234,\n",
    "            select_keys: list=None,\n",
    "            tilt_last: bool=True,\n",
    "            from_tfds: bool=False,\n",
    "            tfds_data_version: str='1.1.0',\n",
    "            num_epochs: int=3):\n",
    "    \"\"\"\n",
    "    This TorNet library function is used to load the data into Tensorflow.\n",
    "    We're going to use the `create_tf_dataset` function from above, \n",
    "    then we'll use `preproc` to preprocess it.\n",
    "\n",
    "    One important note - we tried a bunch of different functions for shuffling \n",
    "    and batching, repeating the dataset, etc. to try to be able to run\n",
    "    many epochs with one function call. It wasn't working.\n",
    "    Even the `drop_remainder=True` that we've added here to ds.batch\n",
    "    seems to not really have an effect, as the model training\n",
    "    still throws an error at the end of training about running out of data.\n",
    "    \"\"\"\n",
    "    \n",
    "    if from_tfds: # fast loader\n",
    "        import tensorflow_datasets as tfds\n",
    "        import tornet.data.tfds.tornet.tornet_dataset_builder # registers 'tornet'\n",
    "        ds = tfds.load('tornet:%s' % tfds_data_version ,split='+'.join(['%s-%d' % (data_type,y) for y in years]))\n",
    "        # Assumes data was saved with tilt_last=True and converts it to tilt_last=False\n",
    "        if not tilt_last:\n",
    "            ds = ds.map(lambda d: pp.permute_dims(d,(0,3,1,2), backend=tf))\n",
    "    else: # Load directly from netcdf files\n",
    "        file_list = query_catalog(data_root, data_type, years, random_state)\n",
    "        ds = create_tf_dataset(file_list,variables=ALL_VARIABLES,n_frames=1, tilt_last=tilt_last) \n",
    "\n",
    "    ds = preproc(ds,weights,include_az,select_keys,tilt_last)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # this has been adjusted to include drop_remainder=True\n",
    "    ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6414f3-a24c-4242-9c0a-0488d29b12ad",
   "metadata": {},
   "source": [
    "## TorNet Baseline CNN Model Definition:\n",
    "\n",
    "As stated in the comment for the code block below, this is just the TorNet model code that was used in the paper.\n",
    "Our goal is to run this model which consists of:\n",
    "- Normalizing the inputs\n",
    "- Adding the coordinate information for CoordConv to work properly\n",
    "- Running 4 VGG blocks which each have CoordConv2D and two MAXPOOL layers\n",
    "- Flatten, then dense layers at the end to get the binary classification output\n",
    "\n",
    "Later on, in our experiments to improve on this model, we'll likely still use some of this code\n",
    "when it comes to preprocessing the data (from a normalization + CoordConv2D standpoint).\n",
    "\n",
    "Notably, in the case of our data augmentation experiments, we'll only really need to change the input dataset\n",
    "(and not any of the model code itself).\n",
    "In comparison, for the YOLO transfer learning experiments, we'll likely not be able to use a good chunk of this\n",
    "dataset (but it might still be useful to use some of the layers made here, for instance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d7d2e8a-6fdf-4017-a395-7a9fa08d8e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is just the TorNet model code that was used in the paper.\n",
    "Goal is to run this model which consists of:\n",
    "- Normalizing the inputs\n",
    "- Adding the coordinate information for CoordConv to work properly\n",
    "- Running 4 VGG blocks which each have CoordConv2D and two MAXPOOL layers\n",
    "- One last block of Conv2D layers and MAXPOOL to get the output probability\n",
    "\"\"\"\n",
    "\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "import keras\n",
    "from tornet.models.keras.layers import CoordConv2D, FillNaNs\n",
    "from tornet.data.constants import CHANNEL_MIN_MAX, ALL_VARIABLES\n",
    "\n",
    "\n",
    "def build_model(shape:Tuple[int]=(120,240,2),\n",
    "                c_shape:Tuple[int]=(120,240,2),\n",
    "                input_variables:List[str]=ALL_VARIABLES,\n",
    "                start_filters:int=64,\n",
    "                l2_reg:float=0.001,\n",
    "                background_flag:float=-3.0,\n",
    "                include_range_folded:bool=True,\n",
    "                head='maxpool'):\n",
    "    # Create input layers for each input_variables\n",
    "    inputs = {}\n",
    "    for v in input_variables:\n",
    "        inputs[v]=keras.Input(shape,name=v)\n",
    "    n_sweeps=shape[2]\n",
    "    \n",
    "    # Normalize inputs and concate along channel dim\n",
    "    normalized_inputs=keras.layers.Concatenate(axis=-1,name='Concatenate1')(\n",
    "        [normalize(inputs[v],v) for v in input_variables]\n",
    "        )\n",
    "\n",
    "    # Replace nan pixel with background flag\n",
    "    normalized_inputs = FillNaNs(background_flag)(normalized_inputs)\n",
    "\n",
    "    # Add channel for range folded gates \n",
    "    if include_range_folded:\n",
    "        range_folded = keras.Input(shape[:2]+(n_sweeps,),name='range_folded_mask')\n",
    "        inputs['range_folded_mask']=range_folded\n",
    "        normalized_inputs = keras.layers.Concatenate(axis=-1,name='Concatenate2')(\n",
    "               [normalized_inputs,range_folded])\n",
    "        \n",
    "    # Input coordinate information\n",
    "    cin=keras.Input(c_shape,name='coordinates')\n",
    "    inputs['coordinates']=cin\n",
    "\n",
    "    x,c = normalized_inputs,cin\n",
    "    \n",
    "    x,c = vgg_block(x,c, filters=start_filters,   ksize=3, l2_reg=l2_reg, n_convs=2, drop_rate=0.1)   # (60,120)\n",
    "    x,c = vgg_block(x,c, filters=2*start_filters, ksize=3, l2_reg=l2_reg, n_convs=2, drop_rate=0.1)  # (30,60)\n",
    "    x,c = vgg_block(x,c, filters=4*start_filters, ksize=3, l2_reg=l2_reg, n_convs=3, drop_rate=0.1)  # (15,30)\n",
    "    x,c = vgg_block(x,c, filters=8*start_filters, ksize=3, l2_reg=l2_reg, n_convs=3, drop_rate=0.1)  # (7,15)\n",
    "    #x,c = vgg_block(x,c, filters=8*start_filters, ksize=3, l2_reg=l2_reg, n_convs=3)  # (3,7)\n",
    "    \n",
    "    if head=='mlp':\n",
    "        # MLP head\n",
    "        x = keras.layers.Flatten()(x) \n",
    "        x = keras.layers.Dense(units = 4096, activation ='relu')(x) \n",
    "        x = keras.layers.Dense(units = 2024, activation ='relu')(x) \n",
    "        output = keras.layers.Dense(1)(x)\n",
    "    elif head=='maxpool':\n",
    "        # Per gridcell\n",
    "        x = keras.layers.Conv2D(filters=512, kernel_size=1,\n",
    "                          kernel_regularizer=keras.regularizers.l2(l2_reg),\n",
    "                          activation='relu')(x)\n",
    "        x = keras.layers.Conv2D(filters=256, kernel_size=1,\n",
    "                          kernel_regularizer=keras.regularizers.l2(l2_reg),\n",
    "                          activation='relu')(x)\n",
    "        x = keras.layers.Conv2D(filters=1, kernel_size=1,name='heatmap')(x)\n",
    "        # Max in scene\n",
    "        output = keras.layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "    return keras.Model(inputs=inputs,outputs=output)\n",
    "\n",
    "\n",
    "def vgg_block(x,c, filters=64, ksize=3, n_convs=2, l2_reg=1e-6, drop_rate=0.0):\n",
    "\n",
    "    for _ in range(n_convs):\n",
    "        x,c = CoordConv2D(filters=filters,\n",
    "                          kernel_size=ksize,\n",
    "                          kernel_regularizer=keras.regularizers.l2(l2_reg),\n",
    "                          padding='same',\n",
    "                          activation='relu')([x,c])\n",
    "    x = keras.layers.MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
    "    c = keras.layers.MaxPool2D(pool_size =2, strides =2, padding ='same')(c)\n",
    "    if drop_rate>0:\n",
    "        x = keras.layers.Dropout(rate=drop_rate)(x)\n",
    "    return x,c\n",
    "\n",
    "\n",
    "def normalize(x,\n",
    "              name:str):\n",
    "    \"\"\"\n",
    "    Channel-wise normalization using known CHANNEL_MIN_MAX\n",
    "    \"\"\"\n",
    "    min_max = np.array(CHANNEL_MIN_MAX[name]) # [2,]\n",
    "    n_sweeps=x.shape[-1]\n",
    "    \n",
    "    # choose mean,var to get approximate [-1,1] scaling\n",
    "    var=((min_max[1]-min_max[0])/2)**2 # scalar\n",
    "    var=np.array(n_sweeps*[var,])    # [n_sweeps,]\n",
    "    \n",
    "    offset=(min_max[0]+min_max[1])/2    # scalar\n",
    "    offset=np.array(n_sweeps*[offset,]) # [n_sweeps,]\n",
    "\n",
    "    return keras.layers.Normalization(mean=offset,\n",
    "                                      variance=var,\n",
    "                                      name='Normalize_%s' % name)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8144dffa-e578-423e-8e11-53b6fb6ce4cb",
   "metadata": {},
   "source": [
    "## Running the Model\n",
    "\n",
    "Ok, we've got all of the TorNet model components figured out and imported (using the helper functions, etc.).\n",
    "[Even getting that working turned out to be tricky - there were dependency issues to resolve, and while we'd \n",
    "like to just be able to import the functions rather than re-copying them here again, that wasn't working so well.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f9c3be5-ebd6-4c7c-83ac-bf8708944ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1731696386.667789    2159 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5564 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37672757-38a1-4e97-a135-c527e7ae02a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ DBZ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ VEL (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ KDP (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ RHOHV (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ZDR (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ WIDTH (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Normalize_DBZ       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ DBZ[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Normalize_VEL       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ VEL[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Normalize_KDP       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ KDP[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Normalize_RHOHV     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ RHOHV[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Normalize_ZDR       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ZDR[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Normalize_WIDTH     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ WIDTH[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Concatenate1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Normalize_DBZ[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)               │            │ Normalize_VEL[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ Normalize_KDP[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ Normalize_RHOHV[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ Normalize_ZDR[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ Normalize_WIDTH[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ isnan (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Isnan</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Concatenate1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ where (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Where</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ isnan[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)               │            │ Concatenate1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ range_folded_mask   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Concatenate2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ where[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)               │            │ range_folded_mas… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coordinates         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d        │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,280</span> │ Concatenate2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CoordConv2D</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,  │            │ coordinates[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)]          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_1      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, │     <span style=\"color: #00af00; text-decoration-color: #00af00\">38,080</span> │ coord_conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CoordConv2D</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,  │            │ coord_conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)]          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ coord_conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ coord_conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_2      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">76,160</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CoordConv2D</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>,  │            │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)]          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_3      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">149,888</span> │ coord_conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CoordConv2D</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>,  │            │ coord_conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)]          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ coord_conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ coord_conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_4      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>,   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">299,776</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CoordConv2D</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,  │            │ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)]           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_5      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>,   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">594,688</span> │ coord_conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CoordConv2D</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,  │            │ coord_conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)]           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_6      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>,   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">594,688</span> │ coord_conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CoordConv2D</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,  │            │ coord_conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)]           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ coord_conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ coord_conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_7      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,189,376</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CoordConv2D</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>,  │            │ max_pooling2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)]           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_8      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,369,024</span> │ coord_conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CoordConv2D</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>,  │            │ coord_conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)]           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_9      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,369,024</span> │ coord_conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CoordConv2D</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>,  │            │ coord_conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)]           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ coord_conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ heatmap (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ heatmap[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling2…</span> │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ DBZ (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│                     │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ VEL (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│                     │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ KDP (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│                     │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ RHOHV (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│                     │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ZDR (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│                     │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ WIDTH (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│                     │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Normalize_DBZ       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ DBZ[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mNormalization\u001b[0m)     │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Normalize_VEL       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ VEL[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mNormalization\u001b[0m)     │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Normalize_KDP       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ KDP[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mNormalization\u001b[0m)     │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Normalize_RHOHV     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ RHOHV[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mNormalization\u001b[0m)     │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Normalize_ZDR       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ ZDR[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mNormalization\u001b[0m)     │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Normalize_WIDTH     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ WIDTH[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mNormalization\u001b[0m)     │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Concatenate1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ Normalize_DBZ[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m12\u001b[0m)               │            │ Normalize_VEL[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ Normalize_KDP[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ Normalize_RHOHV[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ Normalize_ZDR[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ Normalize_WIDTH[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ isnan (\u001b[38;5;33mIsnan\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ Concatenate1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m12\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ where (\u001b[38;5;33mWhere\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ isnan[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │ \u001b[38;5;34m12\u001b[0m)               │            │ Concatenate1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ range_folded_mask   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Concatenate2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ where[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m14\u001b[0m)               │            │ range_folded_mas… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coordinates         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d        │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m, │      \u001b[38;5;34m9,280\u001b[0m │ Concatenate2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mCoordConv2D\u001b[0m)       │ \u001b[38;5;34m64\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m,  │            │ coordinates[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m2\u001b[0m)]          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_1      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m240\u001b[0m, │     \u001b[38;5;34m38,080\u001b[0m │ coord_conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mCoordConv2D\u001b[0m)       │ \u001b[38;5;34m64\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m,  │            │ coord_conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m2\u001b[0m)]          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m120\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ coord_conv2d_1[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m120\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m120\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ coord_conv2d_1[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_2      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m120\u001b[0m,  │     \u001b[38;5;34m76,160\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mCoordConv2D\u001b[0m)       │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m,  │            │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m2\u001b[0m)]          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_3      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m120\u001b[0m,  │    \u001b[38;5;34m149,888\u001b[0m │ coord_conv2d_2[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mCoordConv2D\u001b[0m)       │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m,  │            │ coord_conv2d_2[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m2\u001b[0m)]          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m60\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ coord_conv2d_3[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m60\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m2\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ coord_conv2d_3[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_4      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m60\u001b[0m,   │    \u001b[38;5;34m299,776\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mCoordConv2D\u001b[0m)       │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m,  │            │ max_pooling2d_3[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m2\u001b[0m)]           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_5      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m60\u001b[0m,   │    \u001b[38;5;34m594,688\u001b[0m │ coord_conv2d_4[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mCoordConv2D\u001b[0m)       │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m,  │            │ coord_conv2d_4[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m2\u001b[0m)]           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_6      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m60\u001b[0m,   │    \u001b[38;5;34m594,688\u001b[0m │ coord_conv2d_5[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mCoordConv2D\u001b[0m)       │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m,  │            │ coord_conv2d_5[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m2\u001b[0m)]           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ coord_conv2d_6[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_4[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m2\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ coord_conv2d_6[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_7      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m30\u001b[0m,   │  \u001b[38;5;34m1,189,376\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mCoordConv2D\u001b[0m)       │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m,  │            │ max_pooling2d_5[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m2\u001b[0m)]           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_8      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m30\u001b[0m,   │  \u001b[38;5;34m2,369,024\u001b[0m │ coord_conv2d_7[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mCoordConv2D\u001b[0m)       │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m,  │            │ coord_conv2d_7[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m2\u001b[0m)]           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coord_conv2d_9      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m30\u001b[0m,   │  \u001b[38;5;34m2,369,024\u001b[0m │ coord_conv2d_8[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mCoordConv2D\u001b[0m)       │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m,  │            │ coord_conv2d_8[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m2\u001b[0m)]           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m15\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ coord_conv2d_9[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m15\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_6[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m15\u001b[0m,     │    \u001b[38;5;34m262,656\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m15\u001b[0m,     │    \u001b[38;5;34m131,328\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ heatmap (\u001b[38;5;33mConv2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │        \u001b[38;5;34m257\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ heatmap[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling2…\u001b[0m │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,084,225</span> (30.84 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,084,225\u001b[0m (30.84 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,084,225</span> (30.84 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,084,225\u001b[0m (30.84 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1a005a-757f-4d9a-b4ca-e29426bdefad",
   "metadata": {},
   "source": [
    "Again, as mentioned above, of note here is the learning rate chosen, which is 1.5e-6.\n",
    "\n",
    "We had to test out a bunch of different learning rate choices on a log scale before we found that this scale would not cause gradients to vanish or explode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c56071c5-1a70-4a5b-8fc9-e736ebde6a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=1.5e-6)\n",
    "loss = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "model.compile(loss=loss, optimizer=opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1381c59e-18b7-4b16-ac29-74d4b30ad806",
   "metadata": {},
   "source": [
    "We create a checkpoint saving function just to deal with iPython's many kernel crashes.\n",
    "After each pass through the data and all batches, we'll save the weights, reload the model, and keep going.\n",
    "\n",
    "We'll save the weights in `checkpoints/epoch_{number_of_epoch}.weights.h5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fea1e22b-bc9c-4ed7-807c-baa52e71d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint_creator(checkpoint_path):\n",
    "    # saving the model's weights in case the iPython kernel crashes (which it likes to do)\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                       save_weights_only=True,\n",
    "                                       verbose=1)\n",
    "    return cp_callback\n",
    "\n",
    "def checkpoint_loader(checkpoint_path, model):\n",
    "    model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2112eb5-6cd4-45fe-8d21-83ef2074fc4d",
   "metadata": {},
   "source": [
    "First pass through the data. Again, with each pass, we set it up with:\n",
    "- A batch_size of 64 (to fit the data into GPU memory)\n",
    "- Shuffle the data with a random_state (we pick a new seed each time, but record that seed here so we don't reuse it in a later epoch)\n",
    "- Set up a new checkpoint for each epoch (in case any one epoch of training crashes/fails)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25ddfa68-e121-4440-bacc-125c7f9f00fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = make_tf_loader(data_root = TORNET_DATA_INPUT_FOLDER, \n",
    "                              data_type = \"train\", # or 'test'\n",
    "                              years = list(range(2013, 2023)),\n",
    "                              batch_size = 64, \n",
    "                              weights = None,\n",
    "                              include_az = False,\n",
    "                              random_state = 5678,\n",
    "                              select_keys = ALL_VARIABLES + [\"coordinates\", \"range_folded_mask\"],\n",
    "                              tilt_last = True,\n",
    "                              from_tfds = False,\n",
    "                              tfds_data_version =\"1.1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d79f207a-8752-4bc2-992b-054c1af63860",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731561021.211059     123 service.cc:148] XLA service 0x7f62b4018dc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1731561021.211288     123 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2024-11-13 21:10:21.325432: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1731561021.646291     123 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1731561048.909073     123 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2682/Unknown \u001b[1m8494s\u001b[0m 3s/step - loss: 3.4064\n",
      "Epoch 1: saving model to checkpoints/epoch_1.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 23:31:50.022932: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-11-13 23:31:50.023266: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_16]]\n",
      "2024-11-13 23:31:50.023730: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5090890319797716369\n",
      "2024-11-13 23:31:50.023751: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 17464119409452371891\n",
      "2024-11-13 23:31:50.023775: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1750716295784296344\n",
      "2024-11-13 23:31:50.023779: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 16184661796340794336\n",
      "2024-11-13 23:31:50.023782: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 11418751161415009090\n",
      "2024-11-13 23:31:50.023786: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 7629939211194108882\n",
      "2024-11-13 23:31:50.023789: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 6489020282493185168\n",
      "2024-11-13 23:31:50.023792: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14527890846879760024\n",
      "2024-11-13 23:31:50.023821: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 800837268627791740\n",
      "/usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2682/2682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8495s\u001b[0m 3s/step - loss: 3.4063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f63c40c3b80>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(preprocessed, epochs=1, callbacks=[checkpoint_creator(\"checkpoints/epoch_1.weights.h5\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae6e5125-b437-41f2-9111-3a285ece926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_2 = make_tf_loader(data_root = TORNET_DATA_INPUT_FOLDER, \n",
    "                            data_type = \"train\", # or 'test'\n",
    "                            years = list(range(2013, 2023)),\n",
    "                            batch_size = 64, \n",
    "                            weights = None,\n",
    "                            include_az = False,\n",
    "                            random_state = 9101112,\n",
    "                            select_keys = ALL_VARIABLES + [\"coordinates\", \"range_folded_mask\"],\n",
    "                            tilt_last = True,\n",
    "                            from_tfds = False,\n",
    "                            tfds_data_version =\"1.1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "600fdea0-6a6d-4037-9da3-d2532280621d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2682/Unknown \u001b[1m8202s\u001b[0m 3s/step - loss: 2.8337\n",
      "Epoch 1: saving model to checkpoints/epoch_2.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 03:19:51.753462: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_16]]\n",
      "/usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "2024-11-14 03:19:51.756199: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5090890319797716369\n",
      "2024-11-14 03:19:51.756213: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 17464119409452371891\n",
      "2024-11-14 03:19:51.756221: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1750716295784296344\n",
      "2024-11-14 03:19:51.756224: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 16184661796340794336\n",
      "2024-11-14 03:19:51.756228: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 11418751161415009090\n",
      "2024-11-14 03:19:51.756231: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 7629939211194108882\n",
      "2024-11-14 03:19:51.756234: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 6489020282493185168\n",
      "2024-11-14 03:19:51.756237: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14527890846879760024\n",
      "2024-11-14 03:19:51.756263: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 800837268627791740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2682/2682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8203s\u001b[0m 3s/step - loss: 2.8336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f628c7bfca0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load weights from the previous iteration\n",
    "checkpoint_loader(\"checkpoints/epoch_1.weights.h5\", model)\n",
    "model.fit(resample_2, epochs=1, callbacks=[checkpoint_creator(\"checkpoints/epoch_2.weights.h5\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "436ef159-ef0e-40c6-ae9c-a76364bc963f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 09:51:14.792883: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 117964864 bytes after encountering the first element of size 117964864 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2682/Unknown \u001b[1m8552s\u001b[0m 3s/step - loss: 2.4142\n",
      "Epoch 1: saving model to checkpoints/epoch_3.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 12:13:43.901597: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5090890319797716369\n",
      "2024-11-14 12:13:43.903729: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 17464119409452371891\n",
      "2024-11-14 12:13:43.903745: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1750716295784296344\n",
      "2024-11-14 12:13:43.903749: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 16184661796340794336\n",
      "2024-11-14 12:13:43.903752: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 11418751161415009090\n",
      "2024-11-14 12:13:43.903756: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 7629939211194108882\n",
      "2024-11-14 12:13:43.903758: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 6489020282493185168\n",
      "2024-11-14 12:13:43.903761: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14527890846879760024\n",
      "2024-11-14 12:13:43.903790: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 800837268627791740\n",
      "/usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2682/2682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8553s\u001b[0m 3s/step - loss: 2.4142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f628a401100>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resample_3 = make_tf_loader(data_root = TORNET_DATA_INPUT_FOLDER, \n",
    "                            data_type = \"train\", # or 'test'\n",
    "                            years = list(range(2013, 2023)),\n",
    "                            batch_size = 64, \n",
    "                            weights = None,\n",
    "                            include_az = False,\n",
    "                            random_state = 13141516,\n",
    "                            select_keys = ALL_VARIABLES + [\"coordinates\", \"range_folded_mask\"],\n",
    "                            tilt_last = True,\n",
    "                            from_tfds = False,\n",
    "                            tfds_data_version =\"1.1.0\")\n",
    "\n",
    "# load weights from the previous iteration\n",
    "checkpoint_loader(\"checkpoints/epoch_2.weights.h5\", model)\n",
    "model.fit(resample_3, epochs=1, callbacks=[checkpoint_creator(\"checkpoints/epoch_3.weights.h5\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07a6c1f5-76e9-4f39-823a-b37351998dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2682/Unknown \u001b[1m8814s\u001b[0m 3s/step - loss: 2.0757\n",
      "Epoch 1: saving model to checkpoints/epoch_4.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 14:40:42.147395: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_16]]\n",
      "2024-11-14 14:40:42.150001: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5090890319797716369\n",
      "2024-11-14 14:40:42.150012: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 17464119409452371891\n",
      "2024-11-14 14:40:42.150030: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1750716295784296344\n",
      "2024-11-14 14:40:42.150035: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 16184661796340794336\n",
      "2024-11-14 14:40:42.150039: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 11418751161415009090\n",
      "2024-11-14 14:40:42.150043: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 7629939211194108882\n",
      "2024-11-14 14:40:42.150045: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 6489020282493185168\n",
      "2024-11-14 14:40:42.150048: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14527890846879760024\n",
      "2024-11-14 14:40:42.150356: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 800837268627791740\n",
      "/usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2682/2682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8816s\u001b[0m 3s/step - loss: 2.0757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f6285f38b80>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resample_4 = make_tf_loader(data_root = TORNET_DATA_INPUT_FOLDER, \n",
    "                            data_type = \"train\", # or 'test'\n",
    "                            years = list(range(2013, 2023)),\n",
    "                            batch_size = 64, \n",
    "                            weights = None,\n",
    "                            include_az = False,\n",
    "                            random_state = 17181920,\n",
    "                            select_keys = ALL_VARIABLES + [\"coordinates\", \"range_folded_mask\"],\n",
    "                            tilt_last = True,\n",
    "                            from_tfds = False,\n",
    "                            tfds_data_version =\"1.1.0\")\n",
    "\n",
    "# load weights from the previous iteration\n",
    "checkpoint_loader(\"checkpoints/epoch_3.weights.h5\", model)\n",
    "model.fit(resample_4, epochs=1, callbacks=[checkpoint_creator(\"checkpoints/epoch_4.weights.h5\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f57082c-b48a-47c8-ad8b-5b34682550f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 54 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731657636.601262     158 service.cc:148] XLA service 0x7f2a3c018f60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1731657636.601541     158 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2024-11-15 00:00:36.714626: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1731657637.008340     158 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2024-11-15 00:00:50.275453: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[64,66,120,240]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,64,120,240]{3,2,1,0}, f32[64,66,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 00:00:50.325723: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.050380789s\n",
      "Trying algorithm eng0{} for conv (f32[64,66,120,240]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,64,120,240]{3,2,1,0}, f32[64,66,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "I0000 00:00:1731657661.650837     158 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2682/Unknown \u001b[1m7868s\u001b[0m 3s/step - loss: 1.8027\n",
      "Epoch 1: saving model to checkpoints/epoch_5.weights.h5\n",
      "\u001b[1m2682/2682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7869s\u001b[0m 3s/step - loss: 1.8027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 02:11:40.366837: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-11-15 02:11:40.366870: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_8]]\n",
      "2024-11-15 02:11:40.366887: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 10096804583211940195\n",
      "2024-11-15 02:11:40.366892: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 4071073031941817423\n",
      "2024-11-15 02:11:40.366897: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 15403878188317645847\n",
      "2024-11-15 02:11:40.366901: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 9429846262897810975\n",
      "2024-11-15 02:11:40.366904: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 4583138412789806657\n",
      "2024-11-15 02:11:40.366908: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 11496368188089280258\n",
      "2024-11-15 02:11:40.366911: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 3129206271542983276\n",
      "2024-11-15 02:11:40.366914: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 3349118579839061414\n",
      "2024-11-15 02:11:40.366932: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 9658489388594583432\n",
      "/usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2682/Unknown \u001b[1m7800s\u001b[0m 3s/step - loss: 1.5928\n",
      "Epoch 1: saving model to checkpoints/epoch_6.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 04:21:41.627528: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_8]]\n",
      "2024-11-15 04:21:41.629586: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 10096804583211940195\n",
      "2024-11-15 04:21:41.629597: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 4071073031941817423\n",
      "2024-11-15 04:21:41.629606: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 15403878188317645847\n",
      "2024-11-15 04:21:41.629612: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 9429846262897810975\n",
      "2024-11-15 04:21:41.629615: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 4583138412789806657\n",
      "2024-11-15 04:21:41.629621: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 11496368188089280258\n",
      "2024-11-15 04:21:41.629624: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv /usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "item cancelled. Key hash: 3129206271542983276\n",
      "2024-11-15 04:21:41.629627: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 3349118579839061414\n",
      "2024-11-15 04:21:41.629649: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 9658489388594583432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2682/2682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7800s\u001b[0m 3s/step - loss: 1.5928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 04:21:45.785778: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 117964864 bytes after encountering the first element of size 117964864 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2682/Unknown \u001b[1m7777s\u001b[0m 3s/step - loss: 1.4316\n",
      "Epoch 1: saving model to checkpoints/epoch_7.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 06:31:19.987493: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 10096804583211940195\n",
      "2024-11-15 06:31:19.989670: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 4071073031941817423\n",
      "2024-11-15 06:31:19.989913: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 15403878188317645847\n",
      "2024-11-15 06:31:19.989918: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 9429846262897810975\n",
      "2024-11-15 06:31:19.989922: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 4583138412789806657\n",
      "2024-11-15 06:31:19.989928: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 11496368188089280258\n",
      "2024-11-15 06:31:19.989931: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 3129206271542983276\n",
      "2024-11-15 06:31:19.989935: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 3349118579839061414\n",
      "2024-11-15 06:31:19.989956: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 9658489388594583432\n",
      "/usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2682/2682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7778s\u001b[0m 3s/step - loss: 1.4316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 06:31:25.847160: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 117964864 bytes after encountering the first element of size 117964864 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1423/Unknown \u001b[1m15055s\u001b[0m 11s/step - loss: 1.3196"
     ]
    }
   ],
   "source": [
    "for epoch_num in range(5, 11):\n",
    "    resampled = make_tf_loader(data_root = TORNET_DATA_INPUT_FOLDER, \n",
    "                               data_type = \"train\", # or 'test'\n",
    "                               years = list(range(2013, 2023)),\n",
    "                               batch_size = 64, \n",
    "                               weights = None,\n",
    "                               include_az = False,\n",
    "                               random_state = 21222324 + epoch_num,\n",
    "                               select_keys = ALL_VARIABLES + [\"coordinates\", \"range_folded_mask\"],\n",
    "                               tilt_last = True,\n",
    "                               from_tfds = False,\n",
    "                               tfds_data_version =\"1.1.0\")\n",
    "    checkpoint_loader(\"checkpoints/epoch_{}.weights.h5\".format(str(epoch_num - 1)), model)\n",
    "    model.fit(resampled, epochs=1, callbacks=[checkpoint_creator(\"checkpoints/epoch_{}.weights.h5\".format(epoch_num))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af0dd490-abd5-42ba-8dd8-76f0778721ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 54 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731696404.942044    2274 service.cc:148] XLA service 0x7f7e08005e10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1731696404.942332    2274 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2024-11-15 10:46:45.071143: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1731696405.412703    2274 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1731696428.801904    2274 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     26/Unknown \u001b[1m99s\u001b[0m 3s/step - loss: 1.3240"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 14\u001b[0m\n\u001b[1;32m      2\u001b[0m resampled \u001b[38;5;241m=\u001b[39m make_tf_loader(data_root \u001b[38;5;241m=\u001b[39m TORNET_DATA_INPUT_FOLDER, \n\u001b[1;32m      3\u001b[0m                            data_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# or 'test'\u001b[39;00m\n\u001b[1;32m      4\u001b[0m                            years \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2013\u001b[39m, \u001b[38;5;241m2023\u001b[39m)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m                            from_tfds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m                            tfds_data_version \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m checkpoint_loader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoints/epoch_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(epoch_num \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)), model)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcheckpoints/epoch_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m.weights.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_num\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch_num in range(8, 11):\n",
    "    resampled = make_tf_loader(data_root = TORNET_DATA_INPUT_FOLDER, \n",
    "                               data_type = \"train\", # or 'test'\n",
    "                               years = list(range(2013, 2023)),\n",
    "                               batch_size = 64, \n",
    "                               weights = None,\n",
    "                               include_az = False,\n",
    "                               random_state = 21222324 + epoch_num,\n",
    "                               select_keys = ALL_VARIABLES + [\"coordinates\", \"range_folded_mask\"],\n",
    "                               tilt_last = True,\n",
    "                               from_tfds = False,\n",
    "                               tfds_data_version =\"1.1.0\")\n",
    "    checkpoint_loader(\"checkpoints/epoch_{}.weights.h5\".format(str(epoch_num - 1)), model)\n",
    "    model.fit(resampled, epochs=1, callbacks=[checkpoint_creator(\"checkpoints/epoch_{}.weights.h5\".format(epoch_num))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dad29e27-c4aa-4c3a-a213-222a26e06952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 54 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1434s\u001b[0m 3s/step - AUC: 0.6317 - loss: 2.9407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 11:13:42.744267: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-11-15 11:13:42.744310: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2024-11-15 11:13:42.744320: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 11547744869511264499\n",
      "2024-11-15 11:13:42.744325: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 15588538101070533201\n",
      "2024-11-15 11:13:42.744331: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5916350188155389167\n",
      "2024-11-15 11:13:42.744335: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5719100905002106637\n",
      "2024-11-15 11:13:42.744341: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 13057835299142942990\n",
      "2024-11-15 11:13:42.744345: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14002001117200722730\n",
      "2024-11-15 11:13:42.744349: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 17340242773861678116\n",
      "2024-11-15 11:13:42.744354: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14345316018010961308\n",
      "2024-11-15 11:13:42.744376: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5800315657289053956\n",
      "/usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "/usr/local/lib/python3.9/dist-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 54 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1441s\u001b[0m 3s/step - AUC: 0.6375 - loss: 2.5019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 11:37:43.610944: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2024-11-15 11:37:43.610996: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 11547744869511264499\n",
      "2024-11-15 11:37:43.611001: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 15588538101070533201\n",
      "2024-11-15 11:37:43.611006: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5916350188155389167\n",
      "2024-11-15 11:37:43.611010: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5719100905002106637\n",
      "2024-11-15 11:37:43.611016: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 13057835299142942990\n",
      "2024-11-15 11:37:43.611019: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14002001117200722730\n",
      "2024-11-15 11:37:43.611023: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 17340242773861678116\n",
      "2024-11-15 11:37:43.611026: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14345316018010961308\n",
      "2024-11-15 11:37:43.611042: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5800315657289053956\n",
      "/usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "/usr/local/lib/python3.9/dist-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 54 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "2024-11-15 11:37:46.949457: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 117964864 bytes after encountering the first element of size 117964864 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1442s\u001b[0m 3s/step - AUC: 0.6439 - loss: 2.1461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 12:01:45.791310: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 11547744869511264499\n",
      "2024-11-15 12:01:45.793123: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 15588538101070533201\n",
      "2024-11-15 12:01:45.793133: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5916350188155389167\n",
      "2024-11-15 12:01:45.793137: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5719100905002106637\n",
      "2024-11-15 12:01:45.793145: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 13057835299142942990\n",
      "2024-11-15 12:01:45.793150: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14002001117200722730\n",
      "2024-11-15 12:01:45.793154: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 17340242773861678116\n",
      "2024-11-15 12:01:45.793157: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14345316018010961308\n",
      "2024-11-15 12:01:45.793178: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5800315657289053956\n",
      "/usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "/usr/local/lib/python3.9/dist-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 54 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1477s\u001b[0m 3s/step - AUC: 0.6501 - loss: 1.8581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 12:26:22.954071: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "/usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "2024-11-15 12:26:22.954110: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 11547744869511264499\n",
      "2024-11-15 12:26:22.954116: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 15588538101070533201\n",
      "2024-11-15 12:26:22.954120: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5916350188155389167\n",
      "2024-11-15 12:26:22.954125: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5719100905002106637\n",
      "2024-11-15 12:26:22.954132: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 13057835299142942990\n",
      "2024-11-15 12:26:22.954136: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14002001117200722730\n",
      "2024-11-15 12:26:22.954140: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 17340242773861678116\n",
      "2024-11-15 12:26:22.954142: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14345316018010961308\n",
      "2024-11-15 12:26:22.954163: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5800315657289053956\n",
      "/usr/local/lib/python3.9/dist-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 54 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1495s\u001b[0m 3s/step - AUC: 0.6569 - loss: 1.6297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 12:51:17.833279: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 11547744869511264499\n",
      "2024-11-15 12:51:17.833395: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 15588538101070533201\n",
      "2024-11-15 12:51:17.833405: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5916350188155389167\n",
      "2024-11-15 12:51:17.833410: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5719100905002106637\n",
      "2024-11-15 12:51:17.833491: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 13057835299142942990\n",
      "2024-11-15 12:51:17.833512: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14002001117200722730\n",
      "2024-11-15 12:51:17.833519: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 17340242773861678116\n",
      "2024-11-15 12:51:17.833525: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14345316018010961308\n",
      "2024-11-15 12:51:17.833558: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5800315657289053956\n",
      "/usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "/usr/local/lib/python3.9/dist-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 54 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1512s\u001b[0m 3s/step - AUC: 0.6613 - loss: 1.4592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 13:16:29.819839: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 11547744869511264499\n",
      "/usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "2024-11-15 13:16:29.819878: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 15588538101070533201\n",
      "2024-11-15 13:16:29.819885: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5916350188155389167\n",
      "2024-11-15 13:16:29.819891: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5719100905002106637\n",
      "2024-11-15 13:16:29.819900: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 13057835299142942990\n",
      "2024-11-15 13:16:29.819904: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14002001117200722730\n",
      "2024-11-15 13:16:29.819908: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 17340242773861678116\n",
      "2024-11-15 13:16:29.819912: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14345316018010961308\n",
      "2024-11-15 13:16:29.819931: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5800315657289053956\n",
      "/usr/local/lib/python3.9/dist-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 54 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1519s\u001b[0m 3s/step - AUC: 0.6603 - loss: 1.3301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 13:41:48.748440: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 11547744869511264499\n",
      "2024-11-15 13:41:48.750401: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 15588538101070533201\n",
      "2024-11-15 13:41:48.750409: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5916350188155389167\n",
      "2024-11-15 13:41:48.750413: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5719100905002106637\n",
      "2024-11-15 13:41:48.750421: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 13057835299142942990\n",
      "2024-11-15 13:41:48.750427: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14002001117200722730\n",
      "2024-11-15 13:41:48.750431: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 17340242773861678116\n",
      "2024-11-15 13:41:48.750434: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14345316018010961308\n",
      "2024-11-15 13:41:48.750459: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5800315657289053956\n",
      "/usr/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    }
   ],
   "source": [
    "test_data = make_tf_loader(data_root = TORNET_DATA_INPUT_FOLDER, \n",
    "                              data_type = \"test\",\n",
    "                              years = list(range(2013, 2023)),\n",
    "                              batch_size = 64, \n",
    "                              weights = None,\n",
    "                              include_az = False,\n",
    "                              random_state = 5678,\n",
    "                              select_keys = ALL_VARIABLES + [\"coordinates\", \"range_folded_mask\"],\n",
    "                              tilt_last = True,\n",
    "                              from_tfds = False,\n",
    "                              tfds_data_version =\"1.1.0\")\n",
    "\n",
    "for epoch_num in range(1, 8):\n",
    "    metrics = [keras.metrics.AUC(from_logits=True,name='AUC')]\n",
    "    checkpoint_loader(\"checkpoints/epoch_{}.weights.h5\".format(str(epoch_num)), model)\n",
    "    model.compile(loss=loss, metrics=metrics)\n",
    "    model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bed535-c6bc-48b3-a510-3a0db1369894",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
